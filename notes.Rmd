--- 
title: 'Statistical Modeling: A Tools Approach'
author: "Carlisle Rainey"
date: "`r Sys.Date()`"
output: pdf_document
geometry: margin=2cm
documentclass: book
bibliography:
- book.bib
- packages.bib
biblio-style: apalike
link-citations: yes
description: Lecture notes covering the key tools of regression modeling in political
  science.
site: bookdown::bookdown_site
---

# Week 1

## Class agenda.

**Goal of the class** Make you competent users and consumers (applied and methods papers) of methods beyond least-squares. I'm deliberately avoiding causal-inference methods (matching, DID, etc) because we have a class that covers those specifically that we're offering regularly. I want you to learn a lot about specific tools, but also develop the skills to go and learn more on your own.

We can deviate into any particular topic you'd find helpful.

**Structure of the class** 

We have three sources of information that we'll learn from:

1. *My lectures* I have a set of tools that I want to introduce you to throughout the semester. I think of the lecture as offering "an overview" as well as "my take" on the tool. I will not supply all the details--we don't have enough time and a lecture isn't the ideal medium for deep and subtle ideas. In the past, I have supplied all of my lecture notes to students. However, the research seems clear that student note-taking boosts learning. 
1. *Required readings* For each topic, I have a few readings selected to supply further details or offer a different perspective. I want you to carefully read the required readings, even if they seem familiar. 
1. *Suggested and other readings* I encourage you to engage readings beyond the required set. These might be "easier" readings (e.g., FPP) or more difficult readings (e.g., Greene). In this category, I want you to use judgement. If the required readings are easy, then I recommend moving on *after* seriously engaging the required readings. If the required readings are too difficult, then seek out gentler introductions. You should NOT pursue the suggested or other readings at the expense of the required readings.

**Assessments**

This semester, we have a large set of tools that you must demonstrate that you (1) understand and (2) can implement.

1. Exams: We will have regular exams that require you to implement and explain particular tools. I'm open to suggestions on frequency, but I suggest a *weekly*, open-book, take-home exam with about a one hour time limit. I will grade these as pass/fail. You can re-take a (slightly modified) exam up to three times if you fail.
1. Journal: I want to you to journal throughout the semester. I want you to spend *at least* three hours (hopefully more most weeks) outside of class working on your journal. This journal should have several parts:
   a. Class Notes
   a. Review Exercises
   a. Notes from the required readings, including summaries, reactions, and (especially) questions or flags for ideas you didn't understand. This latter is very important--it will make us all better.
   a. Notes from other readings. I want to give you a bit of space to explore things on your own. You could do a deeper dive on ideas covered carefully in the lectures or readings. Or you could pursue a tangential topic (but keep it somewhat related to class). Again, summaries, reactions, and questions are appropriate. I suggest engaging with reading from substantive course with this class in mind, and record your thoughts in your journal.
   a. Connections throughout the semester.
   a. Explorations of ideas for future projects. 



<!--chapter:end:index.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---

```{r include=FALSE}
library(tidyverse)
```

As I see it, "regression modeling" in political science is a several-step process:

You begin with a substantive understanding of the way the world works.

1. Choose a regression model. I introduce many.
1. Fit a regression model. Maximum likelihood and Markov chain Monte Carlo methods are powerful and general.
1. Evaluate the fit. What are the properties of the procedure? How well does the model match the data?
1. Interpret the model. I emphasize quantities of interest and confidence intervals, but also discuss hypothesis tests.

You then update your understanding of the world.

This week, I introduce our first "engine": maximum likelihood. As a starting point, we use ML to estimate the parameters of Bernoulli, Poisson, and beta distributions (without covariates). I introduce the parametric bootstrap as a tool to obtain confidence intervals. I introduce the invariance property and show how we can use the invariance property to transform the estimated parameters into other quantities of interest. To evaluate the models, we use the predictive distribution.

## Maximum Likelihood

Suppose we have a random sample from a distribution $f(x; \theta)$. We find the maximum likelihood (ML) estimator $\hat{\theta}$ of $\theta$ by maximizing the likelihood of the observed data with respect to $\theta$.

In short, we take the likelihood of the data (given the model and a particular $\theta$) and find the parameter $\theta$ that maximizes it. 

In practice, to make the math and/or computation a bit easier, we manipulate the likelihood function in two ways:

1. Relabel the likelihood function $f(x; \theta) = L(\theta)$, since it's weird to maximize with respect to a "conditioning variable"fixed" variable. (The notation $f(x; \theta)$ suggests $x$ varies for a particular $\theta$.)
1. Work with $\log L(\theta)$ rather than $L(\theta)$. Because $\log()$ is a monotonically increasing function, the $\theta$ that maximizes $L(\theta)$ also maximizes $\log L(\theta)$. 

Suppose we have samples $x_1, x_2, ..., x_N$ from $f(x; \theta)$. Then the joint density/probability is $f(x; \theta) = \prod_{n = 1}^N f(x_n; \theta)$ and $\log L(\theta) = \sum_{n = 1}^N \log \left[ f(x_n; \theta) \right]$. The ML estimator $\hat{\theta}$ of $\theta$ is $\arg \max \log L(\theta)$.

In applied problems, we might be able to simplify $\log L$ substantially. Occasionally, we can find a nice analytical maximum. In many cases, we have a computer find the parameter that maximizes $\log L$.

### Example: Bernoulli Distribution

As a running example, we use the **toothpaste cap problem**:

> We have a toothpaste cap--one with a wide bottom and a narrow top. We're going to toss the toothpaste cap. It can either end up lying on its side, its (wide) bottom, or its (narrow) top. 

> We want to estimate the probability of the toothpaste cap landing on its top.

> We can model each toss as a Bernoulli trial, thinking of each toss as a random variable $X$ where $X \sim \text{Bernoulli}(\pi)$. If the cap lands on its top, we think of the outcome as 1. If not, as 0. 

Suppose we toss the cap $N$ times and observe $k$ tops. What is the ML estimate $\hat{\pi}$ of $\pi$?

According to the model $f(x_i; \pi) = \pi^{x_i} (1 - \pi)^{(1 - x_i)}$. Because the samples are iid, we can find the *joint* distribution $f(x) = f(x_1) \times ... \times f(x_N) = \prod_{i = 1}^N f(x_i)$. We're just multiplying $k$ $\pi$s (i.e., each of the $k$ ones has probability $\pi$) and $(N - k)$ $(1 - \pi)$s (i.e., each of the $N - k$ zeros has probability $1 - \pi$), so that the $f(x; \pi) = \pi^{k} (1 - \pi)^{(N - k)}$.
$$
\text{the likelihood:  } f(x; \pi) =  \pi^{k} (1 - \pi)^{(N - k)}, \text{where } k = \sum_{n = 1}^N x_n \\
$$
Then, we relabel. 
$$
\text{the likelihood:  } L(\pi) = \pi^{k} (1 - \pi)^{(N - k)}\\
$$
Then, we take the log and simplify. 
$$
\text{the log-likelihood:  } \log L(\pi) = k \log (\pi) + (N - k) \log(1 - \pi)\\
$$
To find the ML estimator, we find $\hat{\pi}$ that maximizes $\log L$. 

The code below plots the log-likelihood function using the 8/150 data.

```{r fig.height=3, fig.width=4}
pi <- seq(0.01, 0.99, length.out = 1000)
data <- tibble(pi = pi) %>%
  mutate(log_lik = 18*log(pi) + (150 - 8)*log(1 - pi))
ggplot(data, aes(x = pi, y = log_lik)) + 
  geom_vline(xintercept = 8/150, color = "green") + 
  geom_line() + 
  theme_minimal()
```

In this case, the analytical optimum is easy.

$$
\begin{aligned}
\frac{d \log L}{d\hat{\pi}} = k \left( \frac{1}{\hat{\pi}}\right) + (N - k) \left( \frac{1}{1 - \hat{\pi}}\right)(-1) &= 0\\
\frac{k}{\hat{\pi}} - \frac{N - y}{1 - \hat{\pi}} &= 0 \\
\frac{k}{\hat{\pi}} &= \frac{N - y}{1 - \hat{\pi}} \\
k(1 - \hat{\pi}) &= (N - y)\hat{\pi} \\
k - y\hat{\pi} &= N\hat{\pi} - y\hat{\pi} \\
k  &= N\hat{\pi} \\
\hat{\pi} &= \frac{k}{N} = \text{avg}(x)\\
\end{aligned}
$$
The ML estimator of $\pi$ is the average of the $N$ Bernoulli trials, or, equivalently, the fraction of successes. 

The collected data consist of 150 trials and 8 successes, so the ML estimate of $\pi$ is $\frac{8}{150} \approx 0.053$.

### Example: Poisson Distribution

Suppose we collect $N$ random samples $x = \{x_1, x_2, ..., x_N\}$ and model each draw as a random variable $X \sim \text{Poisson}(\lambda)$. Find the ML estimator of $\lambda$.

$$
\begin{aligned}
\text{Poisson likelihood: } f(x; \lambda) &= \prod_{n = 1}^N \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \\
L(\lambda) &= \prod_{n = 1}^N \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \\
\log L(\lambda) &= \sum_{n = 1}^N \log \left[ \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \right]\\
&= \sum_{n = 1}^N \left[ x_n \log \lambda + (-\lambda) \log e - \log x_n! \right]\\
&= \log \lambda \left[ \sum_{n = 1}^N x_n \right]  -N\lambda + \sum_{n = 1}^N \log (x_n!) \\
\end{aligned}
$$

To find the ML estimator, we find $\hat{\lambda}$ that maximizes $\log L$. In this case, the analytical optimum is easy.

$$
\begin{aligned}
\frac{d \log L}{d\hat{\lambda}} = \frac{1}{\hat{\lambda}} \left[ \sum_{n = 1}^N x_n \right] - N &= 0\\
\frac{1}{\hat{\lambda}} \left[ \sum_{n = 1}^N x_n \right] &= N \\
\left[ \sum_{n = 1}^N x_n \right] &= N \hat{\lambda} \\
\hat{\lambda} &= \frac{ \sum_{n = 1}^N x_n }{N} = \text{avg}(x)  \\
\end{aligned}
$$
The ML estimator for the Poisson distribution is just the average of the samples. 

### Remarks

The ML estimator is extremely common in political science because they are general, fast, and work extremely well. Lots of models that you've heard of, such as logistic regression, are estimated with ML.

We can even obtain ML estimates for the linear regression model. We assume that the observed data are samples from a normal distribution with mean $\mu_n = \alpha + \beta x_n$ and variance $\sigma^2$. For this model, the least-squares estimate that we learned earlier is also the ML estimate. 

### Example: Beta Distribution

Questions:

1.  What is the \textit{support} of the beta distribution? $[0, 1]$
1. Is $y$ a discrete random variable or a continuous random variable? Continuous.
1. What is the pdf/pmf? $f(y_i; \alpha, \beta) = \dfrac{y_i^{\alpha - 1}(1 - y_i)^{\beta - 1}}{B(\alpha, \beta)}$, where $B(\alpha, \beta) = \displaystyle \int_0^1 t^{\alpha - 1}(1 - t)^{\beta - 1}dt$.

With the beta distribution, we add two complications that typically occur when using ML.

1. multiple parameters
1. an intractable log-likelihood

Start with the probability model $Y_i \sim f(y_i; \theta)$. In the case of the beta model, we have $Y_i \sim \text{beta}(y_i; \alpha, \beta)$. The $\alpha$ and $\beta$ here don't have a convenient interpretation. They are "shape" parameters. You can think of $\alpha$ as pushing the distribution to the right and $\beta$ as pushing the distribution to the left.

```{r}
alphas <- c(0.8, 1, 2, 5, 25)
betas <- c(0.8, 1, 2, 5, 25)

x <- seq(0, 1, length.out = 100)

pdfs <- crossing(alpha = alphas, 
                 beta = betas, 
                 x = x) %>%
  mutate(pdf = dbeta(x, alpha, beta)) %>%
  mutate(alpha_lbl = paste0("alpha == ", alpha),
         beta_lbl = paste0("beta == ", beta)) 

ggplot(pdfs, aes(x = x, y = pdf)) + 
  facet_grid(rows = vars(beta_lbl), cols = vars(alpha_lbl), 
             labeller = "label_parsed", scales = "free") + 
  geom_line()

```

We now have two parameters to estimate and we're going to assume that we have multiple observations, so that $y = [y_1, y_2, ,..., y_n]$.

In general, this is how we do ML:

**Step 1** Write down the likelihood function. Recall that we can obtain the joint density of $y_1$ AND $y_2$ AND ... AND $y_n$ by multiplying the probabilities of each (assuming independence).
$$
\begin{aligned}
L(\alpha, \beta) = \displaystyle\prod_{i = 1}^n \overbrace{f(y_i;\alpha, \beta)}^{\text{density}} = \displaystyle\prod_{i = 1}^n \dfrac{y_i^{\alpha - 1}(1 - y_i)^{\beta - 1}}{B(\alpha, \beta)}
\end{aligned}
$$
We see again, as will be usual, that we have this complicated product that will make our lives difficult.

**Step 2** Take the log and simplify.
$$
\begin{aligned}
L(\alpha, \beta) &= \displaystyle\prod_{i = 1}^n \dfrac{y_i^{\alpha - 1}(1 - y_i)^{\beta - 1}}{B(\alpha, \beta)}\\
\log L(\alpha, \beta) &= \displaystyle\sum_{i = 1}^n \log \dfrac{y_i^{\alpha - 1}(1 - y_i)^{\beta - 1}}{B(\alpha, \beta)}\\
&= \displaystyle\sum_{i = 1}^n \left[ \log y_i^{\alpha - 1} + \log (1 - y_i)^{\beta - 1} - \log B(\alpha, \beta)\right]\\
&= \displaystyle\sum_{i = 1}^n \left[ (\alpha - 1)\log y_i + (\beta - 1)\log (1 - y_i) - \log B(\alpha, \beta)\right]\\
&= \displaystyle\sum_{i = 1}^n \left[ (\alpha - 1)\log y_i + (\beta - 1)\log (1 - y_i)\right] - n \log B(\alpha, \beta)\\
\log L(\alpha, \beta) &= (\alpha - 1) \sum_{i = 1}^n \log y_i + (\beta - 1) \sum_{i = 1}^n \log (1 - y_i) - n \log B(\alpha, \beta)
\end{aligned}
$$
**Step 3** Maximize

If we wanted, we could work on this one analytically. 

1. Take the derivative w.r.t. $\alpha$.
1. Take the derivative w.r.t. $\beta$.
1. Set both equal to zero and solve. (Two equations and two unknowns.)

But the last term $B(\alpha, \beta) = \int_0^1 t^{\alpha - 1}(1 - t)^{\beta - 1}dt$ is tricky! So let's do it numerically.

To perform the optimization, we need a data set. For now, let's simulate a fake data set with known parameters

```{r}
y <- rbeta(1000, shape1 = 10, shape2 = 10)
```

Let's plot the log-likelihood function to see what we're dealing with.

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(plotly)

alpha <- seq(0.1, 25, length.out = 100)
beta  <- seq(0.1, 25, length.out = 100)
data <- crossing(alpha, beta) %>%
  mutate(log_lik = alpha*sum(log(y)) + beta*sum(log(1 - y)) - 
           length(y)*log(beta(alpha, beta)))

plot_ly(x = ~alpha, y = ~beta, z = ~log_lik, data = data) %>%
  add_mesh(labels = c("alpha", "beta", "log-likelihood"))
```

```{r fig.height=3, fig.width=4}
ggplot(data, aes(x = alpha, y = beta, z = log_lik)) + 
  geom_contour(bins = 100)
```

Now let's program the log-likelihood function in R to handle the optimization numerically.

```{r}
ll_fn <- function(theta, y) {
  alpha <- theta[1]  # optim() requires a single parameter vector
  beta <- theta[2]
  ll <- alpha*sum(log(y)) + beta*sum(log(1 - y)) - 
           length(y)*log(beta(alpha, beta))
  return(ll)
}
```

Now let's use `optim()` to do the maximization.

```{r}
est <- optim(par = c(1, 1), fn = ll_fn, y = y,
               control = list(fnscale = -1),
               method = "Nelder-Mead")

print(est$par, digits = 3)
```

We can also wrap the `optim()` in a function, to make obtaining the estimates a little bit easier.

```{r}
est_beta <- function(y) {
  est <- optim(par = c(1, 1), fn = ll_fn, y = y,
               control = list(fnscale = -1),
               method = "Nelder-Mead") # for >1d problems
  if (est$convergence != 0) print("Model did not converge!")
  res <- list(est = est$par)
  return(res)
}

ml_est <- est_beta(y)
print(ml_est, digits = 3)
```

<!--chapter:end:01-01-maximum-likelihood.Rmd-->

## The Invariance Property

The parameter $\pi$ has a nice interpretation--it's a probability or the expected fraction of 1s in the long-run. However, the model parameters might not always have nice interpretation. (See the "shape" parameters of the beta distribution.) Fortunately, it's easy to transform the ML estimates of the model parameters into ML estimates of a quantity of interest.

Suppose we obtain an ML estimate $\hat{\theta}$ of a parameter $\theta$. But we also (or instead) want to estimate a transformation $\tau(\theta)$. The we can estimate $\tau(\theta)$ by applying the transformation $\tau$ to the ML estimate $\hat{\theta}$, so that $\widehat{\tau(\theta)} = \hat{\tau} = \tau(\hat{\theta})$.

### Example: Bernoulli Odds

Suppose that we want an ML estimator of the *odds* of getting a top for the toothpaste cap problem. We already used ML to estimate the *probability* $\pi$ of getting a top and came up with $\frac{8}{150} \approx 0.053$. We can directly transform a probability into odds using $\text{odds} = \frac{\pi}{1 - \pi}$. This has a nice interpretation: odds = 2 means that a top is twice as likely as not; odds = 0.5 means that a top is half as likely as not. 

In our case, we can plug our ML estimate of $\pi$ into the transformation to obtain the ML estimate of the odds.
$$
\begin{aligned}
\widehat{\text{odds}} &= \frac{\hat{\pi}}{1 - \hat{\pi}} \\
& = \frac{\frac{8}{150}}{1 - \frac{8}{150}} \\
& = \frac{\frac{8}{150}}{\frac{150}{150} - \frac{8}{150}} \\
& = \frac{\frac{8}{150}}{\frac{142}{150}} \\
& = \frac{8}{142} \\
& \approx 0.056
\end{aligned}
$$
This means that tops are about 0.06 times as likelihood as not-tops. Inverted, you're about $\frac{142}{8} \approx 18$ times more likely to not get a top than get a top.

### Example: Poisson SD 

In this example, we use real data from Hultman, Kathman, and Shannon (2013). They are interested in civilian casualties during civil wars. They write: 

> To gauge the effectiveness of peacekeeping, we explore all intrastate armed conflicts in sub-Saharan Africa from 1991 to 2008 with monthly observations. Conflicts are identified using the Uppsala Conflict Data Program/Peace Research Institute, Oslo (UCDP/PRIO) Armed Conflict Dataset v.4â€“2010 (Gleditsch et al. 2002; Harbom and Wallensteen 2009), which employs a threshold of 25 battle deaths per year. The dataset covers 36 conflicts, 12 of which have a PKO present at some time. Consistent with previous research, we add two years of observations to the end of each conflict episode, as the theoretical processes associated with victimization may continue after the cessation of hostilities (Cunningham, Gleditsch, and Salehyan 2009).

Below are a random sample of 250 observations from their 3,972 monthly observations.

```{r}
civilian_casualties <- c(0, 0, 0, 0, 0, 13, 0, 0, 61, 0, 0, 0, 0, 0, 0, 0, 0,
                          0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 19, 0, 0, 12, 0, 0, 4, 147, 0, 934, 0, 0,
                          42, 0, 24, 124, 0, 1, 0, 0, 0, 145844, 0, 0, 44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                          0, 0, 2, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                          7971, 0, 0, 0, 0, 72, 0, 40, 0, 0, 444, 0, 0, 0, 0, 48, 109, 33, 0, 0, 0, 0,
                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 41, 0, 0, 0, 0, 84, 0, 34, 0, 0, 0,
                          0, 0, 0, 0, 1, 0, 15, 0, 0, 15, 0, 104, 0, 24, 0, 0, 104, 0, 0, 4, 0, 0, 0, 0,
                          0, 12, 41, 0, 0, 37, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                          0, 0, 12, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 8, 21, 0, 0, 0, 0, 25, 0, 0, 0,
                          3, 0, 0, 27, 0, 0, 576, 3, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0,
                          0, 0, 0, 94, 42, 0, 30, 0, 2, 12, 0, 0, 5, 5 ) 
```

We can estimate a single-parameter Poisson model to estimate a mean $\lambda$ and a rate $\frac{1}{\lambda}$. In the case of the Poisson model, the ML estimate $\hat{lambda}$ of $\lambda$ is $\text{avg}(y)$.

```{r}
ml_est <- mean(civilian_casualties)
print(ml_est, digits = 3)
```

The mean is a nice, interpretable parameter, but we might want also want the SD. For the Poisson distribution, the variance equals the mean, so $\text{Var}(y) = \text{E}(y) = \lambda$. Therefore, the SD is $\sqrt{\lambda}$.  

```{r}
# ML estimate of SD
ml_est <- sqrt(630)
print(ml_est, digits = 2)
```

This is the ML estimate of the SD of the data, and it carries all the properties of ML estimators. We're using the invariance property to move from the mean to the SD by a simple transformation.

### Example: Beta Mean and Variance

Now let's see an example of the beta distribution $Y \sim \text{beta}(\alpha, \beta)$. The beta distribution does not have parameters that are easily interpretable in terms of mean and variance. Instead, it has two "shape" parameters $\alpha$ and $\beta$ that are in tension---one pulls the distribution to the left and the other pulls the distribution to the right.

For this example, I use opinion data from the 50 states from Barrilleaux and Rainey (2014). You can find the data here: https://github.com/carlislerainey/aca-opinion/blob/master/Data/mrp_est.csv

To make these data suitable for the beta distribution, I rescaled the observations from a percent to a proportion that ranges from 0 to 1.

```{r}
br <- tibble::tribble(
  ~state_abbr, ~prop_favorable_aca,
         "AL",   0.382711108911823,
         "AK",   0.374428493677838,
         "AZ",   0.396721609154912,
         "AR",   0.361623814680961,
         "CA",   0.560999240847165,
         "CO",   0.450011650633043,
         "CT",   0.522239143634457,
         "DE",   0.524637037667977,
         "DC",   0.853595690161985,
         "FL",    0.47022917052716,
         "GA",   0.460216990024346,
         "HI",    0.61965456264517,
         "ID",   0.282992730179373,
         "IL",   0.550517975187469,
         "IN",   0.421854785281297,
         "IA",   0.454007062646206,
         "KS",   0.394817640911206,
         "KY",   0.336156662764729,
         "LA",   0.425588396620569,
         "ME",   0.472319257331465,
         "MD",   0.583719023711148,
         "MA",   0.531871146279692,
         "MI",   0.509096426714406,
         "MN",   0.497981331879903,
         "MS",   0.468038078521612,
         "MO",   0.420161837905426,
         "MT",   0.351773944902139,
         "NE",   0.365225584190989,
         "NV",   0.459026605256376,
         "NH",    0.43886275738451,
         "NJ",   0.531656835425683,
         "NM",   0.528461049175538,
         "NY",     0.6010574821094,
         "NC",   0.452240849305449,
         "ND",   0.367690453757597,
         "OH",   0.456298880813516,
         "OK",   0.309578750918355,
         "OR",   0.455832591683007,
         "PA",    0.45819440292365,
         "RI",   0.536978574569609,
         "SC",   0.444870259057071,
         "SD",   0.377170366708612,
         "TN",   0.368615233253355,
         "TX",   0.428407014559672,
         "UT",   0.248496577141183,
         "VT",   0.553042362822573,
         "VA",   0.470739058046787,
         "WA",   0.496133477680592,
         "WV",   0.295062675817918,
         "WI",   0.489912969415965,
         "WY",   0.263567780036879
  )
```

Now let's find the ML estimates of the two shape parameters of the beta distribution.

```{r}
# obtain ml estimates
log_lik_fn <- function(par = c(2, 2), y) {
  a <- par[1]  # pulling these out makes the code a bit easier to follow
  b <- par[2]
  log_lik_i <- dbeta(y, shape1 = a, shape2 = b, log = TRUE)
  log_lik <- sum(log_lik_i)
  return(log_lik)
}
opt <- optim(par = c(2, 2), fn = log_lik_fn, y = br$prop_favorable_aca,
             control = list(fnscale = -1))
ml_est <- opt$par
print(ml_est, digits = 3)
```

The mean is given by $\frac{\alpha}{\alpha + \beta}$ and the variance is given by $\frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}$.

We can use the invariance property to obtain ML estimates of the mean and variance using our ML estimates of $\alpha$ and $\beta$.

```{r}
a <- ml_est[1]
b <- ml_est[2]

a/(a + b)  # mean
(a * b)/((a + b)^2 * (a + b + 1))  # var
```

It's worth noting that these correspond closely, *but not exactly* to the observed mean and variance.

```{r}
mean(br$prop_favorable_aca)
var(br$prop_favorable_aca)
```

<!--chapter:end:01-02-invariance-property.Rmd-->


## The Parametric Bootstrap

The parametric bootstrap is a powerful, general tool to obtain confidence intervals for estimates from parametric models. 

Importantly, we are going to lean *pretty heavily* on the assumption that we have a good model of the distribution of the data. (The predictive distribution below allows us to assess this.) There's also a ***non**parametric* bootstrap, which is much more popular. We consider that later in the semester.

Suppose we have a sample $y$ from some known distribution $f(y; \theta)$ and use $y$ to estimate the model parameter(s) $\theta$ or some quantity of interest $\tau(\theta)$. Remember, we can use ML to estimate either.

To compute a confidence interval, we can use a *parametric* bootstrap. To do implement the parametric bootstrap, do the following: 

1. Approximate $f(y; \theta)$ with $\hat{f} = f(y; \hat{\theta})$. Simulate a new outcome $y^{\text{bs}}$ from the estimated distribution. 
1. Re-compute the estimate of interest $\hat{\theta}^{\text{bs}}$ or $\hat{\tau}^{\text{bs}}$ using the bootstrapped outcome variable $y^{\text{bs}}$ rather than the observed outcome $y$.
1. Repeat 1 and 2 many times (say 2,000) to obtain many bootstrapped estimates. To obtain the 95% confidence interval, take the 2.5th and 97.5th percentiles of the estimates. This is known as the percentile method.

### Example: Toothpaste Cap Problm

The code below implements the parametric bootstrap for the toothpaste cap problem. For 2,000 iterations, it draws 150 observations from $Y \sim \text{Bernoulli}(\hat{\pi} = \frac{8}{150})$. For each iteration, it computes the ML estimate of $\pi$ for the bootstrapped data set. Then it computes the percentiles to obtain the confidence interval.

```{r}
n_bs <- 2000
bs_est <- numeric(n_bs)  # a container for the estimates
for (i in 1:n_bs) {
  bs_y <- rbinom(150, size = 1, prob = 8/150)
  bs_est[i] <- mean(bs_y)
}
print(quantile(bs_est, probs = c(0.025, 0.975)), digits = 2)  # 95% ci
```

We leave an evaluation of this confidence interval (i.e., Does it capture $\theta$ 95% of the time?) to later in the semester.

### Example: Beta Distribution

Now let's apply the parametric bootrap to a two-parameter model: the beta distribution.

First, let's simulate a (fake) data set to use.

```{r}
# set parameters
alpha <- 5
beta <- 2

# simulate data
set.seed(1234)
n <- 100
y <- rbeta(n, alpha, beta)
```

Now let's find the ML estimates of the two shape parameters.

```{r}
# obtain ml estimates
log_lik_fn <- function(par = c(2, 2), y) {
  a <- par[1]  # pulling these out makes the code a bit easier to follow
  b <- par[2]
  log_lik_i <- dbeta(y, shape1 = a, shape2 = b, log = TRUE)
  log_lik <- sum(log_lik_i)
  return(log_lik)
}
opt <- optim(par = c(3, 3), fn = log_lik_fn, y = y,
             control = list(fnscale = -1))
ml_est <- opt$par
print(ml_est, digits = 3)
```

Now let's use those ML estimates to perform a parametric bootstrap and find 95% CIs for the shape parameters.

```{r}
# obtain parametric bootstrap 95% ci for alpha and beta
n_bs <- 2000
bs_est <- matrix(NA, nrow = n_bs, ncol = 2)  # a container for the estimates
for (i in 1:n_bs) {
  bs_y <- rbeta(n, shape1 = ml_est[1], shape2 = ml_est[2])
  bs_opt <- optim(par = c(3, 3), fn = log_lik_fn, y = bs_y,
             control = list(fnscale = -1))
  bs_est[i, ] <- bs_opt$par
}
ci <- apply(bs_est, MARGIN = 2, quantile, probs = c(0.025, 0.975))
print(ci, digits = 3)  # 95% ci
```

If instead we cared about the mean of the beta distribution (which is $\frac{\alpha}{\alpha + \beta}$), we can use the parametric bootstrap to obtain a confidence interval for that quantity as well.

```{r}

# obtain parametric bootstrap 95% ci for mean
n_bs <- 2000
bs_est <- numeric(n_bs)  # a container for the estimates
for (i in 1:n_bs) {
  bs_y <- rbeta(n, shape1 = ml_est[1], shape2 = ml_est[2])
  bs_opt <- optim(par = c(3, 3), fn = log_lik_fn, y = bs_y,
             control = list(fnscale = -1))
  bs_alpha <- bs_opt$par[1]
  bs_beta <- bs_opt$par[2]
  bs_est[i] <- bs_alpha/(bs_alpha + bs_beta)
}
print(quantile(bs_est, probs = c(0.025, 0.975)), digits = 2)  # 95% ci

# true mean 
print(alpha/(alpha + beta), digits = 2)
```

<!--chapter:end:01-03-parametric-bootstrap.Rmd-->

## Sampling Distribution

```{r include=FALSE}
library(tidyverse)
```

What's the most important concept in statistical inference? I don't know, but it could be **the sampling distribution**. For effect, let me back off the hedge.

> The most important concept in statistical inference is the **sampling distribution**.

To define a sampling distribution, you need to imagine repeating a study over and over. If each study has a random component (perhaps random sampling or random assignment to treatment and control), then the estimate will differ from study to study. The distribution of the estimates across the studies is called the sampling distribution.

### Example: The Toothpaste Cap Problem

For a given sample of 150 tosses, we recognize the the ML estimate $\hat{\pi}$ does not (usually) exactly equal the parameter $\pi$. Instead, the particular $\hat{\pi}$ that the study produces is draw from a distribution.

Let's illustrate that with a simulation. For these simulations, I suppose that we toss the toothpaste cap 150 times and the chance of a head is 5%.

```{r}
n_sims <- 10
ml_est <- numeric(n_sims)  # a container for the estimates
for (i in 1:n_sims) {
  y <- rbinom(150, size = 1, prob = 0.05)
  ml_est[i] <- mean(y)
}
print(ml_est, digits = 2)
```

As you can see, the ML estimates vary to from sample to sample--different data sets produce different ML estimates. We need a way to create a confidence interval that consistently captures $\theta$. 

If we repeat the simulations a large number of times, we can see an accuracy picture of the sampling distribution via histogram.

```{r fig.height=3, fig.width=4}
n_sims <- 10000
ml_est <- numeric(n_sims)  # a container for the estimates
for (i in 1:n_sims) {
  y <- rbinom(150, size = 1, prob = 0.05)
  ml_est[i] <- mean(y)
}

gg_data <- data.frame(ml_est = ml_est)
ggplot(gg_data, aes(x = ml_est)) + 
  geom_bar()
```

Many of our methods of evaluating an estimator are statements about the sampling distribution of that estimator. In general, we'd like the sampling distribution to be centered over the true parameter of interest and tightly dispersed.

## Bias

Imagine repeatedly sampling and computing the estimate $\hat{\theta}$ of the parameter $\theta$ for each sample. In this thought experiment, $\hat{\theta}$ is a random variable. We say that $\hat{\theta}$ is **biased** if $E(\hat{\theta}) \neq \theta$. We say that $\hat{\theta}$ is **unbiased** if $E(\hat{\theta}) = \theta$. We say that the **bias** of $\hat{\theta}$ is  $E(\hat{\theta}) - \theta$.

Importantly, **ML estimators are not necessarily unbiased**. Of the models we will see in this course, *most* are biased.

### Example: Bernoulli Distribution

For example, we can compute the bias of our ML estimator of $\pi$ in the toothpaste cap problem.

$$
\begin{aligned}
E\left[ \frac{k}{N}\right] &= \frac{1}{N} E(k) = \frac{1}{N} E  \overbrace{ \left( \sum_{n = 1}^N x_n \right) }^{\text{recall } k = \sum_{n = 1}^N x_n } = \frac{1}{N} \sum_{n = 1}^N E(x_n) = \frac{1}{N} \sum_{n = 1}^N \pi = \frac{1}{N}N\pi \\
&= \pi
\end{aligned}
$$

Thus, $\hat{\pi}^{ML}$ is an unbiased estimator of $\pi$ in the toothpaste cap problem.

We can use a Monte Carlo simulation to check this analytical result.

```{r}
set.seed(1234)
n_mc_sims <- 100000
pi_hat <- numeric(n_mc_sims)
for (i in 1:n_mc_sims) {
  y <- rbinom(150, size = 1, prob = 0.05)
  pi_hat[i] <- mean(y)
}

# expected value of pi-hat
mean(pi_hat)

# estimated monte carlo error
sd(pi_hat)/sqrt(n_mc_sims)
```

But notice that the property of unbiasedness does not follow the estimate through transformation. Because the sample is relatively large in this case (150 tosses), the bias is small, but detectable with 100,000 Monte Carlo simulations

```{r}
odds_hat <- pi_hat/(1 - pi_hat)

# actual odds
0.05/(1 - 0.05)

# expected value of odds-hat
mean(odds_hat)

# estimated monte carlo error
sd(odds_hat)/sqrt(n_mc_sims)

# the z-statistic
(mean(odds_hat) - 0.05/0.95)/(sd(odds_hat)/sqrt(n_mc_sims))
```


### Example: Poisson Distribution

Using math almost identical to the toothpaste cap problem, we can show that the ML estimator $\hat{\lambda} = \text{avg}(x)$ is an unbiased estimator of $\lambda$. 

We can also illustrate the unbiasedness with a computer simulation.

```{r}
lambda <- 4.0      # the parameter we're trying to estimate
sample_size <- 10  # the sample size we're using in each "study"

n_mc_sims <- 10000  # the number of times we repeat the "study"
lambda_hat <- numeric(n_mc_sims)  # a container 
for (i in 1:n_mc_sims) {
  x <- rpois(sample_size, lambda = lambda)
  lambda_hat[i] <- mean(x)
}

# expected value of lambda-hat
mean(lambda_hat)

# estimated monte carlo error
sd(lambda_hat)/sqrt(n_mc_sims)
```

## Consistency

Imagine taking a sample of size $N$ and computing the estimate $\hat{\theta}_N$ of the parameter $\theta$. We say that $\hat{\theta}$ is a **consistent** estimator of $\theta$ if $\hat{\theta}$ converges in probability to $\theta$.

Intuitively, this means the following:

1. For a large enough sample, the estimator returns the exact right answer.
1. For a large enough sample, the estimate $\hat{\theta}$ does not vary any more, but collapses onto a single point and that point is $\theta$.

Under weak, but somewhat technical, assumptions that usually hold, ML estimators are consistent. 

Given that we always have finite samples, why is consistency valuable? In short, it's not valuable, directly. However, consistent estimators tend to be decent with small samples. 

But it does not follow that consistent estimators work well in small samples. However, as a rough guideline, consistent estimators work well for small samples. However, whether they actually work well in any particular situation needs a more careful investigation.

### Example: Illustrative

To illustrate the concept of consistency, consider this estimator of the population mean $\hat{\mu}^{\text{silly}} = \frac{\sum_{i = 1}^N x_i}{N + 10}$. While this estimator is biased, it is a consistent estimator.

```{r message=FALSE, warning=FALSE}
population <- c(1, 2, 3, 4, 5)
sample_sizes <- c(2, 5, 10, 100, 1000, 10000, 100000)
n_mc_sims <- 30  # for each sample size
results_list <- list()  # grow with each iteration; slow, but easy
for (i in 1:length(sample_sizes)) {
  ml_est_i <- numeric(n_mc_sims)
  for (j in 1:n_mc_sims) {
    x <- sample(population, sample_sizes[i], replace = TRUE)
    ml_est_i[j] <- sum(x)/(sample_sizes[i] + 10)
  }
  results_list[[i]] <- data.frame(sample_size = sample_sizes[i],
                             ml_est = ml_est_i)
}
results <- dplyr::bind_rows(results_list) 

ggplot(results, aes(x = sample_size, y = ml_est)) + 
  geom_hline(yintercept = mean(population)) + 
  geom_jitter() + 
  scale_x_log10()
```



### Example: Bernoulli Odds

There are two ways to see consistency for the Bernoulli. First, unless our sample size is a multiple of 20, it is impossible to obtain an estimated odds of 0.05/(1 - 0.05). Second, in small samples, the ML estimate of the odds is biased. As the sample size increases, the bias shrinks and the estimates collapse toward (and eventually onto) the true value.


```{r message=FALSE, warning=FALSE}
sample_sizes <- c(2:100, 250, 400, 500, 750, 1000)
n_mc_sims <- 10  # for each sample size
results_list <- list()  # grow with each iteration; slow, but easy
for (i in 1:length(sample_sizes)) {
  ml_est_i <- numeric(n_mc_sims)
  for (j in 1:n_mc_sims) {
    x <- rbinom(sample_sizes[i], 1, prob = 0.05)
    pi_hat <- mean(x)
    ml_est_i[j] <- pi_hat/(1 - pi_hat)
  }
  results_list[[i]] <- data.frame(sample_size = sample_sizes[i],
                             ml_est = ml_est_i)
}
results <- dplyr::bind_rows(results_list) 

ggplot(results, aes(x = sample_size, y = ml_est)) + 
  geom_hline(yintercept = 0.05/(1 - 0.05)) + 
  geom_jitter(alpha = 0.5, shape = 19) + 
  scale_x_log10() 

ggplot(results, aes(x = sample_size, y = ml_est)) + 
  geom_hline(yintercept = 0.05/(1 - 0.05)) + 
  scale_x_log10() + 
  geom_smooth()
```

<!--chapter:end:01-04-bias-and-consistency.Rmd-->

```{r include=FALSE}
library(tidyverse)
```

## Predictive Distribution

In Bayesian statistics, a popular tool for model evaluation is the posterior predictive distribution. But we might use an analogous approach for models fit with maximum likelihood. 

The predictive distribution is just the distribution given the ML estimates. Using our notation above, the predictive distribution is $f(y; \hat{\theta})$. 

When you perform a parametric bootstrap, you are resampling from this predictive distribution. Here, we're going to use it for a different purpose: to understand and evaluate our model.

In my view, the predictive distribution is the best way to (1) understand, (2) evaluate, and then (3) improve models.

You can use the predictive distribution as follows:

1. Fit your model with maximum likelihood.
1. Simulate a new outcome variable using the estimated model parameters (i.e., $f(y; \hat{theta})$). Perhaps simulate a handful for comparison.
1. Compare the simulated outcome variable(s) to the observed outcome variables.

### Example: Poisson Distribution

Earlier, we fit a Poisson distribution to a sample of data from Hultman, Kathman, and Shannon (2013).

```{r include=FALSE}
civilian_casualties <- c(0, 0, 0, 0, 0, 13, 0, 0, 61, 0, 0, 0, 0, 0, 0, 0, 0,
                          0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 19, 0, 0, 12, 0, 0, 4, 147, 0, 934, 0, 0,
                          42, 0, 24, 124, 0, 1, 0, 0, 0, 145844, 0, 0, 44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                          0, 0, 2, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                          7971, 0, 0, 0, 0, 72, 0, 40, 0, 0, 444, 0, 0, 0, 0, 48, 109, 33, 0, 0, 0, 0,
                          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 41, 0, 0, 0, 0, 84, 0, 34, 0, 0, 0,
                          0, 0, 0, 0, 1, 0, 15, 0, 0, 15, 0, 104, 0, 24, 0, 0, 104, 0, 0, 4, 0, 0, 0, 0,
                          0, 12, 41, 0, 0, 37, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                          0, 0, 12, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 8, 21, 0, 0, 0, 0, 25, 0, 0, 0,
                          3, 0, 0, 27, 0, 0, 576, 3, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0,
                          0, 0, 0, 94, 42, 0, 30, 0, 2, 12, 0, 0, 5, 5 ) 
```

```{r}
ml_est <- mean(civilian_casualties)
print(ml_est, digits = 3)

n <- length(civilian_casualties)
y_pred <- rpois(n, lambda = ml_est)
print(y_pred[1:30])
print(civilian_casualties[1:30])
```
Simply printing a few results, we can immediately see a problem with data, when compared with the raw data

To see it even more clearly, we can create a histogram of the observed and simulated data.

```{r fig.height=3, fig.width=6, message=FALSE, warning=FALSE}
library(patchwork)

p1 <- qplot(civilian_casualties)
p2 <- qplot(y_pred)

p1 + p2
```
These data sets are so different that the plots are difficult to read, so we might put the x-axes on the log scale. Note, though, that the two plots have very different ranges on the axes.

```{r fig.height=3, fig.width=6, message=FALSE, warning=FALSE}
p1 <- qplot(civilian_casualties) + scale_x_log10()
p2 <- qplot(y_pred) + scale_x_log10()

p1 + p2
```

For a more accurate and complete comparison, let's simulate five fake data sets and use common axes

```{r message=FALSE, warning=FALSE}
observed_data <- tibble(civilian_casualties, type = "observed")

sim_list <- list()
for (i in 1:5) {
  y_pred <- rpois(n, lambda = ml_est)
  sim_list[[i]] <- tibble(civilian_casualties = y_pred, 
                          type = paste0("simulated #", i))
}
gg_data <- bind_rows(sim_list) %>%
  bind_rows(observed_data) %>%
  glimpse()

ggplot(gg_data, aes(x = civilian_casualties)) + 
  geom_histogram() + 
  facet_wrap(vars(type)) + 
  scale_x_log10()
```
The fit of this model is almost absurd.

### Example: Beta Distribution

Now let's return to our beta model of states' opinions toward the ACA in the `br` data frame we loaded earlier.

```{r include=FALSE}
# load data
br <- tibble::tribble(
  ~state_abbr, ~prop_favorable_aca,
         "AL",   0.382711108911823,
         "AK",   0.374428493677838,
         "AZ",   0.396721609154912,
         "AR",   0.361623814680961,
         "CA",   0.560999240847165,
         "CO",   0.450011650633043,
         "CT",   0.522239143634457,
         "DE",   0.524637037667977,
         "DC",   0.853595690161985,
         "FL",    0.47022917052716,
         "GA",   0.460216990024346,
         "HI",    0.61965456264517,
         "ID",   0.282992730179373,
         "IL",   0.550517975187469,
         "IN",   0.421854785281297,
         "IA",   0.454007062646206,
         "KS",   0.394817640911206,
         "KY",   0.336156662764729,
         "LA",   0.425588396620569,
         "ME",   0.472319257331465,
         "MD",   0.583719023711148,
         "MA",   0.531871146279692,
         "MI",   0.509096426714406,
         "MN",   0.497981331879903,
         "MS",   0.468038078521612,
         "MO",   0.420161837905426,
         "MT",   0.351773944902139,
         "NE",   0.365225584190989,
         "NV",   0.459026605256376,
         "NH",    0.43886275738451,
         "NJ",   0.531656835425683,
         "NM",   0.528461049175538,
         "NY",     0.6010574821094,
         "NC",   0.452240849305449,
         "ND",   0.367690453757597,
         "OH",   0.456298880813516,
         "OK",   0.309578750918355,
         "OR",   0.455832591683007,
         "PA",    0.45819440292365,
         "RI",   0.536978574569609,
         "SC",   0.444870259057071,
         "SD",   0.377170366708612,
         "TN",   0.368615233253355,
         "TX",   0.428407014559672,
         "UT",   0.248496577141183,
         "VT",   0.553042362822573,
         "VA",   0.470739058046787,
         "WA",   0.496133477680592,
         "WV",   0.295062675817918,
         "WI",   0.489912969415965,
         "WY",   0.263567780036879
  )
```

```{r}
# obtain ml estimates
log_lik_fn <- function(par = c(2, 2), y) {
  a <- par[1]  # pulling these out makes the code a bit easier to follow
  b <- par[2]
  log_lik_i <- dbeta(y, shape1 = a, shape2 = b, log = TRUE)
  log_lik <- sum(log_lik_i)
  return(log_lik)
}
opt <- optim(par = c(2, 2), fn = log_lik_fn, y = br$prop_favorable_aca,
             control = list(fnscale = -1))
ml_est <- opt$par
```

Now let's simulate some fake data from the predictive distribution and compare that to the observed data

```{r message=FALSE, warning=FALSE}

observed_data <- br %>%
  mutate(type = "observed")

n <- nrow(br)
sim_list <- list()
for (i in 1:5) {
  y_pred <- rbeta(n, shape1 = ml_est[1], shape2 = ml_est[2])
  sim_list[[i]] <- tibble(prop_favorable_aca = y_pred, 
                          type = paste0("simulated #", i))
}
gg_data <- bind_rows(sim_list) %>%
  bind_rows(observed_data) 

ggplot(gg_data, aes(x = prop_favorable_aca)) + 
  geom_histogram() + 
  facet_wrap(vars(type)) + 
  scale_x_log10()
```

On the whole, we see hear a fairly close correspondence between the observed and simulated data. That suggests that our model is a good description of the data.





<!--chapter:end:01-05-predictive-distribution.Rmd-->



## Exercises

From this week, you should be able to...

1. Starting with a given distribution (pdf or pmf), find the log-likihood function.
1. Optimize the log-likelihood function analytically or numerically (i.e., using `optim()`).
1. Use the invariance property of ML estimator to transform parameter estimates into estimates of quantities of interest.
1. Use the parametric bootstrap to compute confidence intervals.
1. Describe a "sampling distribution" and illustrate it with a computer simulation.
1. Describe the concepts of "bias" and "consistency." Are ML estimates unbaised? Consistent? Under what conditions?
1. Use the predictive distribution to evaluate models.

### Questions About the Exponential Distribution

```{exercise, label="ml-exponential"}
Suppose we collect $N$ random samples $x = \{x_1, x_2, ..., x_N\}$ and model each draw as a random variable $X \sim \text{exponential}(\lambda)$ with pdf $f(x_n | \lambda) = \lambda e^{-\lambda x_n}$. 

1. Find the maximum likelihood estimator of $\lambda$.
1. Perform a Monte Carlo simulation to assess the bias in the ML estimator of $\lambda$ you found above. Use 100,000 Monte Carlo simulations. Estimate the Monte Carlo error as $\frac{\text{SD of estimates}}{\sqrt{\text{number of MC simulations}}}$. Try a small sample size (e.g., $N = 5$ and a large (e.g., $N = 1,000$). Demonstrate analytically that the estimate is biased.
1. Is the ML estimator of $\lambda$ consistent? Why or why not?
1. We interpret the parameter $\lambda$ as a "rate." Find the ML estimate of the mean, which is the reciprocal of the rate. Is this estimate unbiased? Consistent?
```  

<details><summary>Solution</summary>
1. The math follows the Poisson example closely. However, the solution is the inverse--$\hat{\lambda} = \frac{N}{\sum_{n = 1}^N x_n } = \frac{1}{\text{avg}(x)}$.
</details>

```{exercise}
Suppose a data set `x <- c(0.306, 0.023, 0.0471, 0.042, 0.227)`. Model this data set using an exponential distribution and estimate the rate $\lambda$ using maximum likelihood. Find the estimates in two ways. First, compute the ML estimates using the analytical solution you found above. Second, derive the log-likelihood function, plot it, and use `optim()` to find the maximum. Show that the two solutions agree.
```

```{exercise}
Load the `cancer` data frame from the survival package in R using `data(cancer, package="survival")`. Estimate both the rate and the mean. Use the parametric bootstrap to obtain a 95% confidence interval for each. Use the predictive distribution to evaluate the fit of the model. Do the simulated data sets seems to match the observed data sets?
```

<!--- # remove for exam
```{exercise, label="ml-govt-duration"}
Obtain the data for King, Alta, Burns, and Laver (2008) from Dataverse: https://doi.org/10.7910/DVN/CVJPAN. Find the file `coalcold.tab`. The variable `DURAT` gives the number of months that the government lasted. Model these durations as an exponential distributions. 

1. Estimate the rate $\lambda$ and mean (reciprocal of the rate). Use the parametric bootstrap to obtain a 95% confidence interval for each.
1. Simulate fake data from the predictive distribution and graphically compare these draws to the observed values. How do the observed data deviate from the model?
```
--->

```{exercise}
Obtain the data for Barrilleaux and Rainey (2014) from GitHub: https://github.com/carlislerainey/aca-opinion/blob/master/Data/mrp_est.csv. Find the file `mrp_est.csv`. The variable `percent_supporting_expansion` gives the the percent of each state that supports expanding Medicaid under the ACA. 

1. Model the distribution of *proportions* (you'll need to transform the variable from a percent to a proportion) as a beta distribution. Estimate the two shape parameters using maximum likelihood. Transform these estimates into estimates of the mean and SD. Compute a 95% confidence interval for the mean and SD using the parametric bootstap.
1. Simulate fake data from the predictive distribution and graphically compare these draws to the observed values. How do the observed data deviate from the model? Compare the the observed and simulated distributions in several ways, such as histograms, ecdf plots, two-number summaries, five-number summaries, etc. Look for ways that the simulated data sets consistently deviate from the observed.
```

```{exercise}
Suppose a discrete uniform distribution from 0 to $K$. The pdf is $f(x; K) = \frac{1}{K}$ for $x \in \{0, 1, ..., K\}$. Suppose I have three samples from the distribution: 676, 459, and 912. Find the ML estimate of $K$.
```

```{exercise}
**DeGroot and Schervish, q. 9, p. 425.** Suppose a distribution $f(x; \theta) = \theta x^{\theta - 1}$ for $0 < x < 1$ and $\theta > 0$. Find the ML estimator of $\theta$.
```

```{exercise}
Remember that the estimate $\hat{\lambda} = \text{avg}(y)$ for the Poisson distribution is unbiased. Remember that $E(y) = \lambda$ and $\text{SD}(y)$ is $\sqrt{\lambda}$. By the invariance properity, the ML estimator of $SD(y) = \sqrt{\hat{\lambda}}$. Use a Monte Carlo simulation to assess whether (and how much) this estimator of the SD is biased. Be sure to experiment with the sample size of y (e.g., N = 5, N = 200, etc.), but use a large number of Monte Carlo simulations (e.g., 100,000).
```



<!--chapter:end:01-99-exercises.Rmd-->

```{r include=FALSE}
library(tidyverse)
```

# Week 2

This week, we introduce the following tools.

1. **engine** Bayesian inference
1. **distributions** normal, uniform
1. **confidence intervals** posterior simulation, Bayesian credible intervals, percentile intervals.
1. **quantities of interest** transforming posterior simulations
1. **evaluating models** posterior predictive distribution

## Bayesian Inference

Bayesian inference follows a simple recipe:

1. Choose a distribution for the data.
1. Choose a distribution to describe your prior beliefs.
1. Update the prior distribution upon observing the data by computing the posterior distribution. 

In simple examples, we can implement this process analytically and obtain a closed-form posterior. In most applied cases, we can only *sample from* the posterior distribution, but this turns out to work almost as well.

### Mechanics

Suppose a random sample from a distribution $f(x; \theta)$ that depends on the unknown parameter $\theta$. 

Bayesian inference models our *beliefs* about the unknown parameter $\theta$ as a distribution. It answers the question: what should we believe about $\theta$, given the observed samples $x = \{x_1, x_2, ..., x_n\}$ from $f(x; \theta)$? These beliefs are simply the conditional distribution $f(\theta \mid x)$.

By Bayes' rule, $\displaystyle f(\theta \mid x) = \frac{f(x \mid \theta)f(\theta)}{f(x)} = \frac{f(x \mid \theta)f(\theta)}{\displaystyle \int_{-\infty}^\infty f(x \mid \theta)f(\theta) d\theta}$.

$$
\displaystyle \underbrace{f(\theta \mid x)}_{\text{posterior}} = \frac{\overbrace{f(x \mid \theta)}^{\text{likelihood}} \times \overbrace{f(\theta)}^{\text{prior}}}{\displaystyle \underbrace{\int_{-\infty}^\infty f(x \mid \theta)f(\theta) d\theta}_{\text{normalizing constant}}}
$$
There are four parts to a Bayesian analysis.

1. $f(\theta \mid x)$. "The posterior;" what we're trying to find. This distribution models our beliefs about parameter $\theta$ given the data $x$. 
1. $f(x \mid \theta)$. "The likelihood." This distribution model conditional density/probability of the data $x$ given the parameter $\theta$. We need to invert the conditioning in order to find the posterior.
1. $f(\theta)$. "The prior;" our beliefs about $\theta$ prior to observing the sample $x$. 
1. $f(x) =\int_{-\infty}^\infty f(x \mid \theta)f(\theta) d\theta$. A normalizing constant. Recall that the role of the normalizing constant is to force the distribution to integrate or sum to one. Therefore, we can safely ignore this constant until the end, and then find proper normalizing constant. 

It's convenient to choose a **conjugate** prior distribution that, when combined with the likelihood, produces a posterior from the same family as the prior. 

The resulting distribution is a complete and correct summary of our updated beliefs about the parameters.

### Posterior Summaries

If we want to summarize the posterior distribution, then we can (though we lose some information).

First, we might summarize the distribution using a single point to make a "best guess" at the parameter of interest. We have three options:

1. *The posterior mean*. The posterior mean minimizes a squared-error loss function.
1. *The posterior median*: The posterior median minimizes an absolute loss function where the cost of guessing $a$ when the truth is $\alpha$ is $|a - \alpha|$. Intuitively, there's a 50% chance that $\pi$ falls above and below the posterior median. 
1. *The posterior mode*: The posterior mode is the most likely value of $\pi$, so it minimizes a loss function that penalizes all misses equally.

Second, we might find an $100(1 - \alpha)\%$ credible interval, by finding an interval that that integrates to $(1 - \alpha)$. That is, a region that has a $100(1 - \alpha)\%$ chance of containing the parameter. This interval is not unique; there are many. However, *one* $100(1 - \alpha)\%$  credible interval is the $100(1 - \alpha)\%$ *percentile* credible interval. Construct this interval by finding the $100\frac{\alpha}{2}th$ percentile and the $100(1 - \frac{\alpha}{2})th$ percentile. For example, if we want a 90% credible interval, we would find the 5th and 95th percentiles.


### Posterior Simulation

In some cases, we have an analytical solution for the posterior---we can write down the equation for the posterior. But in most cases, we cannot write down the posterior. Perhaps unexpectedly, it is usually easier to *sample from* the distribution that write down the posterior in closed form.

But notice that the samples are almost as good as the closed-form solution. We can sample from the distribution many times and then draw the histogram, compute the average, and find the percentiles. Except for sampling error that we can make arbitraryily small, these correspond to the posterior density, the posterior mean, and the 95% (percentile) credible interval.

## Example: Bernoulli

As a running example, we use the **toothpaste cap problem**:

> We have a toothpaste cap--one with a wide bottom and a narrow top. We're going to toss the toothpaste cap. It can either end up lying on its side, its (wide) bottom, or its (narrow) top. 

> We want to estimate the probability of the toothpaste cap landing on its top.

> We can model each toss as a Bernoulli trial, thinking of each toss as a random variable $X$ where $X \sim \text{Bernoulli}(\pi)$. If the cap lands on its top, we think of the outcome as 1. If not, as 0. 

> Suppose we toss the cap $N$ times and observe $k$ tops. What is the posterior distribution of $\pi$?

### The Likelihood {#likelihood}

According to the model $f(x_i \mid \pi) = \pi^{x_i} (1 - \pi)^{(1 - x_i)}$. Because the samples are iid, we can find the *joint* distribution $f(x) = f(x_1) \times ... \times f(x_N) = \prod_{i = 1}^N f(x_i)$. We're just multiplying $k$ $\pi$s (i.e., each of the $k$ ones has probability $\pi$) and $(N - k)$ $(1 - \pi)$s (i.e., each of the $N - k$ zeros has probability $1 - \pi$), so that the $f(x | \pi) = \pi^{k} (1 - \pi)^{(N - k)}$.

$$
\text{the likelihood:  } f(x | \pi) = \pi^{k} (1 - \pi)^{(N - k)}, \text{where } k = \sum_{n = 1}^N x_n \\
$$

### The Prior

The prior describes your beliefs about $\pi$ *before* observing the data.

Here are some questions that we might ask ourselves the following questions:

1. What's the most likely value of $\pi$? *Perhaps 0.15.*
1. Are our beliefs best summarizes by a distribution that's skewed to the left or right? *To the right.*
1. $\pi$ is about _____, give or take _____ or so. *Perhaps 0.17 and 0.10.*
1. There's a 25% chance that $\pi$ is less than ____. *Perhaps 0.05.*
1. There's a 25% chance that $\pi$ is greater than ____. *Perhaps 0.20*.

Given these answers, we can sketch the pdf of the prior distribution for $\pi$.

```{r echo=FALSE, fig.height=3, fig.width=6, message=FALSE, warning=FALSE}
library(tidyverse)
#library(xkcd)
#library(extrafont)
#loadfonts()

set.seed(1234)
a <- 3

b <- 15
s <- rbeta(200, a, b)
gg_data <- tibble(s)
ggplot(gg_data, aes(x = s)) + 
  geom_density() + 
  theme_minimal() + 
  scale_x_continuous(limits = c(0, 1)) +
  annotate(geom = "text", x = .35, y = 1, 
           label = "probably not larger than 0.3", 
           #family = "Humor Sans", 
           hjust = "left", 
           color = "grey50") + 
  annotate(geom = "segment", x = .34, xend = 0.30, y = 0.9, yend = 0.5, 
           color = "grey50") + 
  annotate(geom = "text", x = .05, y = 1.5, 
           label = "might be close to zero", 
           #family = "Humor Sans", 
           hjust = "left", 
           color = "grey50") + 
  annotate(geom = "segment", x = .1, xend = 0.03, y = 1.3, yend = 0.3, 
           color = "grey50") + 
    annotate(geom = "text", x = 0.18, y = 5.1, 
           label = "most likely around 0.15", 
           #family = "Humor Sans", 
           hjust = "left", 
           color = "grey50") + 
  annotate(geom = "segment", x = .14, xend = 0.17, y = 4.9, yend = 5.05, 
           color = "grey50") + 
  theme(text = element_text(size = 12), #, family = "Humor Sans"),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) + 
  scale_y_continuous(breaks = NULL) + 
  labs(title = "A Sketch of Our Prior Beleifs About pi",
       x = "pi",
       y = "Prior Density") 

```

Now we need to find a density function that matches these prior beliefs. For this Bernoulli model, the *beta distribution* is the conjugate prior. While a conjugate prior is not crucial in general, it makes the math much more tractable. 

So then what beta distribution captures our prior beliefs?

There's a code snippet [here](https://gist.github.com/carlislerainey/45414e0d9f22e4e1960449402e6a8048) to help you explore different beta distributions.

After some exploration, I find that setting the parameters $\alpha$ and $\beta$ of the beta distribution to 3 and 15, respectively, captures my prior beliefs about the probability of getting a top.

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(data_frame(x = seq(0, 1, length.out = 100))) + 
  stat_function(fun = dbeta, args = list(shape1 = 3, shape2 = 15)) + 
  labs(title = "pdf of the beta(3, 15) distribution", x = "pi", y = "prior density")
```
The pdf of the beta distribution is $f(x) = \frac{1}{B(\alpha, \beta)} x^{\alpha - 1}(1 - x)^{\beta - 1}$. Remember that $B()$ is the beta function, so $\frac{1}{B(\alpha, \beta)}$ is a constant.

Let's denote our chosen values of $\alpha = 3$ and $\beta = 15$ as $\alpha^*$ and $\beta^*$. As we see in a moment, it's convenient distinguish the parameters in the prior distribution from other parameters.

$$
\text{the prior:  }  f(\pi) = \frac{1}{B(\alpha^*, \beta^*)} \pi^{\alpha^* - 1}(1 - \pi)^{\beta^* - 1}
$$

### The Posterior

Now we need to compute the posterior by multiplying the likelihood times the prior and then finding the normalizing constant.
$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\overbrace{f(x \mid \pi)}^{\text{likelihood}} \times \overbrace{f(\pi)}^{\text{prior}}}{\displaystyle \underbrace{\int_{-\infty}^\infty f(x \mid \pi)f(\pi) d\pi}_{\text{normalizing constant}}} \\
$$
Now we plug in the likelihood, plug in the prior, and denote the normalizing constant as $C_1$ to remind ourselves that it's just a constant.

$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\overbrace{\left[ \pi^{k} (1 - \pi)^{(N - k) }\right] }^{\text{likelihood}} \times \overbrace{ \left[ \frac{1}{B(\alpha^*, \beta^*)} \pi^{\alpha^* - 1}(1 - \pi)^{\beta^* - 1} \right] }^{\text{prior}}}{\displaystyle \underbrace{C_1}_{\text{normalizing constant}}} \\
$$

Now we need to simplify the right-hand side. 

First, notice that the term $\frac{1}{B(\alpha^*, \beta^*)}$ in the numerator is just a constant. We can incorporate that constant term with $C_1$ by multiplying top and bottom by $B(\alpha^*, \beta^*)$ and letting $C_2 = C_1 \times B(\alpha^*, \beta^*)$.

$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\overbrace{\left[ \pi^{k} (1 - \pi)^{(N - k) }\right] }^{\text{likelihood}} \times  \left[ \pi^{\alpha^* - 1}(1 - \pi)^{\beta^* - 1} \right] }{\displaystyle \underbrace{C_2}_{\text{new normalizing constant}}} \\
$$

Now we can collect the exponents with base $\pi$ and the exponents with base $(1 - \pi)$.

$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\left[ \pi^{k} \times \pi^{\alpha^* - 1} \right] \times  \left[ (1 - \pi)^{(N - k) } \times (1 - \pi)^{\beta^* - 1} \right] }{ C_2} \\
$$
Recalling that $x^a \times x^b = x^{a + b}$, we combine the powers.

$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\left[ \pi^{(\alpha^* + k) - 1} \right] \times  \left[ (1 - \pi)^{[\beta^* + (N - k)] - 1} \right] }{ C_2} \\
$$

Because we're clever, we notice that this is *almost* a beta distribution with $\alpha = (\alpha^* + k)$ and $\beta = [\beta^* + (N - k)]$. If $C_2 = B(\alpha^* + k, \beta^* + (N - k))$, then the posterior is *exactly* a $\text{beta}(\alpha^* + k, \beta^* + [N - k]))$ distribution. 

This is completely expected. We chose a beta distribution for the prior because it would give us a beta posterior distribution. For simplicity, we can denote the parameter for the beta posterior as $\alpha^\prime$ and $\beta^\prime$, so that $\alpha^\prime = \alpha^* + k$ and $\beta^\prime = \beta^* + [N - k]$

$$
\begin{aligned}
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} &= \frac{ \pi^{\overbrace{(\alpha^* + k)}^{\alpha^\prime} - 1}  \times  (1 - \pi)^{\overbrace{[\beta^* + (N - k)]}^{\beta^\prime} - 1}  }{ B(\alpha^* + k, \beta^* + [N - k])} \\
&= \frac{ \pi^{\alpha^\prime - 1}  \times  (1 - \pi)^{\beta^\prime - 1}  }{ B(\alpha^\prime, \beta^\prime)}, \text{where } \alpha^\prime = \alpha^* + k \text{ and } \beta^\prime = \beta^* + [N - k]
\end{aligned}
$$

This is an elegant, simple solution. To obtain the parameters for the beta posterior distribution, we just add the number of tops (Bernoulli successes) to the prior value for $\alpha$ and the number of not-tops (sides and bottoms; Bernoulli failures) to the prior value for $\beta$.

Suppose that I tossed the toothpaste cap 150 times and got 8 tops.

```{r fig.height=3, fig.width=8, message=FALSE, warning=FALSE}

# prior parameters
alpha_prior <- 3
beta_prior <- 15

# data 
k <- 8
N <- 150

# posterior parameters
alpha_posterior <- alpha_prior + k
beta_posterior <- beta_prior + N - k

# plot prior and posterior
gg_prior <- ggplot() + 
  stat_function(fun = dbeta, args = list(shape1 = alpha_prior, shape2 = beta_prior)) + 
  labs(title = "prior distribution", x = "pi", y = "prior density")
gg_posterior <- ggplot() + 
  stat_function(fun = dbeta, args = list(shape1 = alpha_posterior, shape2 = beta_posterior)) + 
  labs(title = "posterior distribution", x = "pi", y = "posterior density")

library(patchwork)
gg_prior + gg_posterior

```

### Point Estimates

1. *The posterior mean*. The posterior mean minimizes a squared-error loss function. That is, the cost of guessing $a$ when the truth is $\alpha$ is $(a - \alpha)^2$. In the case of the beta posterior, it's just $\dfrac{\alpha^\prime}{\alpha^\prime + \beta^\prime}$. For our prior and data, we have $\dfrac{3 + 8}{(3 + 8) + (15 + 150 - 8)} \approx 0.065$.
1. *The posterior median*: The posterior median minimizes an absolute loss function where the cost of guessing $a$ when the truth is $\alpha$ is $|a - \alpha|$. Intuitively, there's a 50% chance that $\pi$ falls above and below the posterior median. In the case of the beta posterior, it's just $\dfrac{\alpha^\prime - \frac{1}{3}}{\alpha^\prime + \beta^\prime - \frac{2}{3}}$ (for $\alpha^\prime, \beta^\prime > 1$). For our prior and data, we have $\dfrac{3 + 8 -\frac{1}{3}}{(3 + k) + (15 + 150 - 8) - \frac{2}{3}} \approx 0.064$.
1. *The posterior mode*: The posterior mode is the most likely value of $\pi$, so it minimizes a loss function that penalizes all misses equally. In the case of the beta posterior, it's just $\dfrac{\alpha^\prime - 1}{\alpha^\prime + \beta^\prime - 2}$ (for $\alpha^\prime, \beta^\prime > 1$). For our prior and data, we have $\dfrac{3 + 8 - 1}{(3 + k) + (15 + 150 - 8) - 2} \approx 0.060$.

### Credible Interval

Using the percentile method, we can compute the 90% and 95% credible intervals with `qbeta()`.

```{r}
# 90% credible interval
qbeta(c(0.05, 0.95), 3 + 8, 15 + 150 - 8)

# 95% credible interval
qbeta(c(0.025, 0.975), 3 + 8, 15 + 150 - 8)
```

### Simulation

We don't need to use simulation here---we have the simple closed-form posterior. However, let's see how simulation would work.

```{r}
post_sims <- rbeta(1000, 3 + 8, 15 + 150 - 8)

# posterior density
gg_data <- tibble(post_sims)
ggplot(gg_data, aes(x = post_sims)) + 
  geom_histogram()

# posterior mean
mean(post_sims)

# credible interval
```


## Example: Poisson Distribution

Suppose we collect $N$ random samples $x = \{x_1, x_2, ..., x_N\}$ and model each draw as a random variable $X \sim \text{Poisson}(\lambda)$. Find the posterior distribution of $\lambda$ for the gamma prior distribution. Hint: the gamma distribution is the conjugate prior for the Poisson likelihood.

$$
\begin{aligned}
\text{Poisson likelihood: } f(x \mid \lambda) &= \prod_{n = 1}^N \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \\
&= \displaystyle \left[ \frac{1}{\prod_{n = 1}^N x_n !} \right]e^{-N\lambda}\lambda^{\sum_{n = 1}^N x_n}
\end{aligned}
$$

$$
\text{Gamma prior: } f( \lambda; \alpha^*, \beta^*) = \frac{{\beta^*}^{\alpha^*}}{\Gamma(\alpha^*)} \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}
$$
To find the posterior, we multiply the likelihood times the prior and normalize. Because the gamma prior distribution is the conjugate prior for the Poisson likelihood, we know that the posterior will be a gamma distribution.

$$
\begin{aligned}
\text{Gamma posterior: } f( \lambda  \mid x) &= \frac{\left( \displaystyle \left[ \frac{1}{\prod_{n = 1}^N x_n !} \right]e^{-N\lambda}\lambda^{\sum_{n = 1}^N x_n}\right) \times \left( \left[ \frac{{\beta^*}^{\alpha^*}}{\Gamma(\alpha^*)} \right] \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}\right)}{C_1} \\
\end{aligned}
$$
Because $x$, $\alpha_*$, and $\beta$ are fixed, the terms in square brackets are constant, so we can safely consider those part of the normalizing constant.

$$
\begin{aligned}
&= \frac{\left( \displaystyle  e^{-N\lambda}\lambda^{\sum_{n = 1}^N x_n}\right) \times \left( \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}\right)}{C_2} \\
\end{aligned}
$$
Now we can collect the exponents with the same base.

$$
\begin{aligned}
&= \frac{\left( \lambda^{\alpha^* - 1} \times \lambda^{\sum_{n = 1}^N x_n}\right) \times \left( \displaystyle  e^{-N\lambda} \times e^{-\beta^*\lambda} \right)}{C_2} \\
&= \frac{\lambda^{ \overbrace{\left[ \alpha^* + \sum_{n = 1}^N x_n \right]}^{\alpha^\prime} - 1}  e^{-\overbrace{[\beta^* + N]}^{\beta^\prime}\lambda} }{C_2} \\
\end{aligned}
$$

We recognize this as *almost* a Gamma distribution with parameters $\alpha^\prime = \alpha^* +  \sum_{n = 1}^N x_n$ and $\beta^\prime = \beta^* + N$. Indeed, if $\frac{1}{C_2} = \frac{{\beta^\prime}^{\alpha^\prime}}{\Gamma(\alpha^{\prime})}$, then we have exactly a gamma distribution. 

$$
\begin{aligned}
&= \frac{{\beta^\prime}^{\alpha^\prime}}{\Gamma(\alpha^{\prime})} \lambda^{ \alpha^\prime - 1}  e^{-\beta^\prime\lambda}, \text{where } \alpha^\prime = \alpha^* +  \sum_{n = 1}^N x_n \text{ and } \beta^\prime = \beta^* + N
\end{aligned}
$$

Like the Bernoulli likelihood with the beta prior, the Poisson likelihood withe the gamma prior gives a nice result. We start with values parameters of the gamma distribution $\alpha = \alpha^*$ and $\beta + \beta^*$ so that the gamma prior distribution describes our prior beliefs about the parameters $\lambda$ of the Poisson distribution. Then we add the sum of the data $x$ to $\alpha^*$ and the number of samples $N$ to $\beta^*$ to obtain the parameters of the gamma posterior distribution.

The code below shows the posterior distribution 

```{r fig.height=3, fig.width=8, message=FALSE, warning=FALSE}
# set see to make reproducible
set.seed(1234)

# prior parameters
alpha_prior <- 3
beta_prior <- 3

# create an "unknown" value of lambda to estimate
lambda <- 2

# generate a data set
N <- 5  # number of samples
x <- rpois(N, lambda = lambda)
print(x)  # print the data set

# posterior parameters
alpha_posterior <- alpha_prior + sum(x)
beta_posterior <- beta_prior + N

# plot prior and posterior
gg_prior <- ggplot() + xlim(0, 5) + 
  stat_function(fun = dgamma, args = list(shape = alpha_prior, rate = beta_prior)) + 
  labs(title = "prior distribution", x = "lambda", y = "prior density")
gg_posterior <- ggplot() + xlim(0, 5) + 
  stat_function(fun = dgamma, args = list(shape = alpha_posterior, rate = beta_posterior)) + 
  labs(title = "posterior distribution", x = "lambda", y = "posterior density")
gg_prior + gg_posterior  # uses patchwork package

# posterior mean: alpha/beta
alpha_posterior/beta_posterior

# posterior mode: (alpha - 1)/beta for alpha > 1
(alpha_posterior - 1)/beta_posterior

# 90% credible interval
qgamma(c(0.05, 0.95), alpha_posterior, beta_posterior)

# 95% credible interval
qgamma(c(0.025, 0.975), alpha_posterior, beta_posterior)

```

In the case of the posterior median, there is no closed-form solution, even though we know the form of the posterior. We can use simulation to obtain the median.

```{r}
# posterior median: no closed form, so simulate
post_sims <- rgamma(1000, alpha_posterior, beta_posterior)
median(post_sims)
```

### Remarks

Bayesian inference presents two difficulties. 

1. Choosing a prior. 
   a. It can be hard to actually construct a prior distribution. It's challenging when dealing with a single parameter. It becomes much more difficult when dealing with several or many parameters.
   a. Priors are subjective, so that one researcher's prior might not work for another. 
1. Computing the posterior. Especially for many-parameter problems and non-conjugate priors, computing the posterior can be nearly intractable.

However, there are several practical solutions to these difficulties.

1. Choosing a prior.
    a. We can use a "uninformative" or constant prior. Sometimes, we can use an improper prior that doesn't integrate to one, but places equal prior weight on all values. 
    a. We can use an extremely diffuse prior. For example, if we wanted to estimate the average height in a population in inches, we might use a normal distribution centered at zero with an SD of 10,000. This prior says: "The average height is about zero, give or take 10,000 inches or so."
    a. We can use an informative prior, but conduct careful robustness checks to assess whether the conclusions depend on the particular prior.
    a. We can use a weakly informative prior, that rules places meaningful prior weight on all the plausible values and little prior weight only on the most implausible values. As a guideline, you might create a weakly informative prior by doubling or tripling the SD of the informative prior.
1. Computing the posterior.
    a. While analytically deriving the posterior becomes intractable for most applied problems, it's relatively easy to *sample* from the posterior distribution for many models. 
    a. Algorithms like Gibbs samplers, MCMC, and HMC make this sampling procedure straightforward for a given model.
    a. Software such as Stan make sampling easy to set up and very fast. Post-processing R packages such as tidybayes make it each to work with the posterior simulations.
    

<!--chapter:end:02-01-bayes.Rmd-->

## MCMC

MCMC, or Markov chain Monte Carlo, is a generic algorithm to sample from posterior distributions. There are many variants, and the details are largely beyond the scope of the class. For most applied problems, there's a default approach that's standard for the situation. For most of our cases, it will be HMC using Stan, for example.

However, here is the key idea. 

1. You hand the sampler your likelihood and prior.
1. It explores the posterior in in a way such that subsequent draws are correlated.
1. But if you run the sampler long enough (say 10,000 iterations), then you can treat the serially correlated samples as independent draws from the posterior distribution.

These samplers allow us to skip the normalization step.

### Metropolis-Hastings

Consider the 

```{r}
n <- 3
y <- rnorm(n, 1, 3)

log_lik <- function(par) {
  log_lik <- sum(dnorm(y, mean = par, sd = 3), log = TRUE)
  return(log_lik)
}

log_prior <- function(par) {
  log_prior <- dcauchy(par, location = 10, scale = 1, log = TRUE)
  return(log_prior)
}

log_post <- function(par) {
  log_lik(par) + log_prior(par)
}


library(MCMCpack)
s <- MCMCmetrop1R(theta.init = 0, fun = log_post)

hist(s)
plot(s)
```

### Mechanics

Suppose a random sample from a distribution $f(x; \theta)$ that depends on the unknown parameter $\theta$. 

Bayesian inference models our *beliefs* about the unknown parameter $\theta$ as a distribution. It answers the question: what should we believe about $\theta$, given the observed samples $x = \{x_1, x_2, ..., x_n\}$ from $f(x; \theta)$? These beliefs are simply the conditional distribution $f(\theta \mid x)$.

By Bayes' rule, $\displaystyle f(\theta \mid x) = \frac{f(x \mid \theta)f(\theta)}{f(x)} = \frac{f(x \mid \theta)f(\theta)}{\displaystyle \int_{-\infty}^\infty f(x \mid \theta)f(\theta) d\theta}$.

$$
\displaystyle \underbrace{f(\theta \mid x)}_{\text{posterior}} = \frac{\overbrace{f(x \mid \theta)}^{\text{likelihood}} \times \overbrace{f(\theta)}^{\text{prior}}}{\displaystyle \underbrace{\int_{-\infty}^\infty f(x \mid \theta)f(\theta) d\theta}_{\text{normalizing constant}}}
$$
There are four parts to a Bayesian analysis.

1. $f(\theta \mid x)$. "The posterior;" what we're trying to find. This distribution models our beliefs about parameter $\theta$ given the data $x$. 
1. $f(x \mid \theta)$. "The likelihood." This distribution model conditional density/probability of the data $x$ given the parameter $\theta$. We need to invert the conditioning in order to find the posterior.
1. $f(\theta)$. "The prior;" our beliefs about $\theta$ prior to observing the sample $x$. 
1. $f(x) =\int_{-\infty}^\infty f(x \mid \theta)f(\theta) d\theta$. A normalizing constant. Recall that the role of the normalizing constant is to force the distribution to integrate or sum to one. Therefore, we can safely ignore this constant until the end, and then find proper normalizing constant. 

It's convenient to choose a **conjugate** prior distribution that, when combined with the likelihood, produces a posterior from the same family. 

As a running example, we use the **toothpaste cap problem**:

> We have a toothpaste cap--one with a wide bottom and a narrow top. We're going to toss the toothpaste cap. It can either end up lying on its side, its (wide) bottom, or its (narrow) top. 

> We want to estimate the probability of the toothpaste cap landing on its top.

> We can model each toss as a Bernoulli trial, thinking of each toss as a random variable $X$ where $X \sim \text{Bernoulli}(\pi)$. If the cap lands on its top, we think of the outcome as 1. If not, as 0. 

> Suppose we toss the cap $N$ times and observe $k$ tops. What is the posterior distribution of $\pi$?

#### The Likelihood {#likelihood}

According to the model $f(x_i \mid \pi) = \pi^{x_i} (1 - \pi)^{(1 - x_i)}$. Because the samples are iid, we can find the *joint* distribution $f(x) = f(x_1) \times ... \times f(x_N) = \prod_{i = 1}^N f(x_i)$. We're just multiplying $k$ $\pi$s (i.e., each of the $k$ ones has probability $\pi$) and $(N - k)$ $(1 - \pi)$s (i.e., each of the $N - k$ zeros has probability $1 - \pi$), so that the $f(x | \pi) = \pi^{k} (1 - \pi)^{(N - k)}$.

$$
\text{the likelihood:  } f(x | \pi) = \pi^{k} (1 - \pi)^{(N - k)}, \text{where } k = \sum_{n = 1}^N x_n \\
$$

#### The Prior

The prior describes your beliefs about $\pi$ *before* observing the data.

Here are some questions that we might ask ourselves the following questions:

1. What's the most likely value of $\pi$? *Perhaps 0.15.*
1. Are our beliefs best summarizes by a distribution that's skewed to the left or right? *To the right.*
1. $\pi$ is about _____, give or take _____ or so. *Perhaps 0.17 and 0.10.*
1. There's a 25% chance that $\pi$ is less than ____. *Perhaps 0.05.*
1. There's a 25% chance that $\pi$ is greater than ____. *Perhaps 0.20*.

Given these answers, we can sketch the pdf of the prior distribution for $\pi$.

```{r echo=FALSE, fig.height=3, fig.width=6, message=FALSE, warning=FALSE}
library(tidyverse)
#library(xkcd)
#library(extrafont)
#loadfonts()

set.seed(1234)
a <- 3

b <- 15
s <- rbeta(200, a, b)
gg_data <- tibble(s)
ggplot(gg_data, aes(x = s)) + 
  geom_density() + 
  theme_minimal() + 
  scale_x_continuous(limits = c(0, 1)) +
  annotate(geom = "text", x = .35, y = 1, 
           label = "probably not larger than 0.3", 
           #family = "Humor Sans", 
           hjust = "left", 
           color = "grey50") + 
  annotate(geom = "segment", x = .34, xend = 0.30, y = 0.9, yend = 0.5, 
           color = "grey50") + 
  annotate(geom = "text", x = .05, y = 1.5, 
           label = "might be close to zero", 
           #family = "Humor Sans", 
           hjust = "left", 
           color = "grey50") + 
  annotate(geom = "segment", x = .1, xend = 0.03, y = 1.3, yend = 0.3, 
           color = "grey50") + 
    annotate(geom = "text", x = 0.18, y = 5.1, 
           label = "most likely around 0.15", 
           #family = "Humor Sans", 
           hjust = "left", 
           color = "grey50") + 
  annotate(geom = "segment", x = .14, xend = 0.17, y = 4.9, yend = 5.05, 
           color = "grey50") + 
  theme(text = element_text(size = 12), #, family = "Humor Sans"),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) + 
  scale_y_continuous(breaks = NULL) + 
  labs(title = "A Sketch of Our Prior Beleifs About pi",
       x = "pi",
       y = "Prior Density") 

```

Now we need to find a density function that matches these prior beliefs. For this Bernoulli model, the *beta distribution* is the conjugate prior. While a conjugate prior is not crucial in general, it makes the math much more tractable. 

So then what beta distribution captures our prior beliefs?

There's a code snippet [here](https://gist.github.com/carlislerainey/45414e0d9f22e4e1960449402e6a8048) to help you explore different beta distributions (also in the appendix).

After some exploration, we find that setting the parameters $\alpha$ and $\beta$ of the beta distribution to 3 and 15, respectively, captures our prior beliefs about the probability of getting a top.

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(data_frame(x = seq(0, 1, length.out = 100))) + 
  stat_function(fun = dbeta, args = list(shape1 = 3, shape2 = 15)) + 
  labs(title = "pdf of the beta(3, 15) distribution", x = "pi", y = "prior density")
```
The pdf of the beta distribution is $f(x) = \frac{1}{B(\alpha, \beta)} x^{\alpha - 1}(1 - x)^{\beta - 1}$. Remember that $B()$ is the beta function, so $\frac{1}{B(\alpha, \beta)}$ is a constant.

Let's denote our chosen values of $\alpha = 3$ and $\beta = 15$ as $\alpha^*$ and $\beta^*$. As we see in a moment, it's convenient distinguish the parameters in the prior distribution from other parameters.

$$
\text{the prior:  }  f(\pi) = \frac{1}{B(\alpha^*, \beta^*)} \pi^{\alpha^* - 1}(1 - \pi)^{\beta^* - 1}
$$

#### The Posterior

Now we need to compute the posterior by multiplying the likelihood times the prior and then finding the normalizing constant.
$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\overbrace{f(x \mid \pi)}^{\text{likelihood}} \times \overbrace{f(\pi)}^{\text{prior}}}{\displaystyle \underbrace{\int_{-\infty}^\infty f(x \mid \pi)f(\pi) d\pi}_{\text{normalizing constant}}} \\
$$
Now we plug in the likelihood, plug in the prior, and denote the normalizing constant as $C_1$ to remind ourselves that it's just a constant.

$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\overbrace{\left[ \pi^{k} (1 - \pi)^{(N - k) }\right] }^{\text{likelihood}} \times \overbrace{ \left[ \frac{1}{B(\alpha^*, \beta^*)} \pi^{\alpha^* - 1}(1 - \pi)^{\beta^* - 1} \right] }^{\text{prior}}}{\displaystyle \underbrace{C_1}_{\text{normalizing constant}}} \\
$$

Now we need to simplify the right-hand side. 

First, notice that the term $\frac{1}{B(\alpha^*, \beta^*)}$ in the numerator is just a constant. We can incorporate that constant term with $C_1$ by multiplying top and bottom by $B(\alpha^*, \beta^*)$ and letting $C_2 = C_1 \times B(\alpha^*, \beta^*)$.

$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\overbrace{\left[ \pi^{k} (1 - \pi)^{(N - k) }\right] }^{\text{likelihood}} \times  \left[ \pi^{\alpha^* - 1}(1 - \pi)^{\beta^* - 1} \right] }{\displaystyle \underbrace{C_2}_{\text{new normalizing constant}}} \\
$$

Now we can collect the exponents with base $\pi$ and the exponents with base $(1 - \pi)$.

$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\left[ \pi^{k} \times \pi^{\alpha^* - 1} \right] \times  \left[ (1 - \pi)^{(N - k) } \times (1 - \pi)^{\beta^* - 1} \right] }{ C_2} \\
$$
Recalling that $x^a \times x^b = x^{a + b}$, we combine the powers.

$$
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} = \frac{\left[ \pi^{(\alpha^* + k) - 1} \right] \times  \left[ (1 - \pi)^{[\beta^* + (N - k)] - 1} \right] }{ C_2} \\
$$

Because we're clever, we notice that this is *almost* a beta distribution with $\alpha = (\alpha^* + k)$ and $\beta = [\beta^* + (N - k)]$. If $C_2 = B(\alpha^* + k, \beta^* + (N - k))$, then the posterior is *exactly* a $\text{beta}(\alpha^* + k, \beta^* + [N - k]))$ distribution. 

This is completely expected. We chose a beta distribution for the prior because it would give us a beta posterior distribution. For simplicity, we can denote the parameter for the beta posterior as $\alpha^\prime$ and $\beta^\prime$, so that $\alpha^\prime = \alpha^* + k$ and $\beta^\prime = \beta^* + [N - k]$

$$
\begin{aligned}
\text{the posterior: } \displaystyle \underbrace{f(\pi \mid x)}_{\text{posterior}} &= \frac{ \pi^{\overbrace{(\alpha^* + k)}^{\alpha^\prime} - 1}  \times  (1 - \pi)^{\overbrace{[\beta^* + (N - k)]}^{\beta^\prime} - 1}  }{ B(\alpha^* + k, \beta^* + [N - k])} \\
&= \frac{ \pi^{\alpha^\prime - 1}  \times  (1 - \pi)^{\beta^\prime - 1}  }{ B(\alpha^\prime, \beta^\prime)}, \text{where } \alpha^\prime = \alpha^* + k \text{ and } \beta^\prime = \beta^* + [N - k]
\end{aligned}
$$

This is an elegant, simple solution. To obtain the parameters for the beta posterior distribution, we just add the number of tops (Bernoulli successes) to the prior value for $\alpha$ and the number of not-tops (sides and bottoms; Bernoulli failures) to the prior value for $\beta$.

Suppose that I tossed the toothpaste cap 150 times and got 8 tops.

```{r fig.height=3, fig.width=8, message=FALSE, warning=FALSE}

# prior parameters
alpha_prior <- 3
beta_prior <- 15

# data 
k <- 8
N <- 150

# posterior parameters
alpha_posterior <- alpha_prior + k
beta_posterior <- beta_prior + N - k

# plot prior and posterior
gg_prior <- ggplot() + 
  stat_function(fun = dbeta, args = list(shape1 = alpha_prior, shape2 = beta_prior)) + 
  labs(title = "prior distribution", x = "pi", y = "prior density")
gg_posterior <- ggplot() + 
  stat_function(fun = dbeta, args = list(shape1 = alpha_posterior, shape2 = beta_posterior)) + 
  labs(title = "posterior distribution", x = "pi", y = "posterior density")

library(patchwork)
gg_prior + gg_posterior

```

#### Bayesian Point Estimates

In this section, we want *point estimates*---a best guess at the parameter---not a full posterior distribution. 

We have three options:

1. *The posterior mean*. The posterior mean minimizes a squared-error loss function. That is, the cost of guessing $a$ when the truth is $\alpha$ is $(a - \alpha)^2$. In the case of the beta posterior, it's just $\dfrac{\alpha^\prime}{\alpha^\prime + \beta^\prime}$. For our prior and data, we have $\dfrac{3 + 8}{(3 + k) + (15 + 150 - 8)} \approx 0.065$.
1. *The posterior median*: The posterior median minimizes an absolute loss function where the cost of guessing $a$ when the truth is $\alpha$ is $|a - \alpha|$. Intuitively, there's a 50% chance that $\pi$ falls above and below the posterior median. In the case of the beta posterior, it's just $\dfrac{\alpha^\prime - \frac{1}{3}}{\alpha^\prime + \beta^\prime - \frac{2}{3}}$ (for $\alpha^\prime, \beta^\prime > 1$). For our prior and data, we have $\dfrac{3 + 8 -\frac{1}{3}}{(3 + k) + (15 + 150 - 8) - \frac{2}{3}} \approx 0.064$.
1. *The posterior mode*: The posterior mode is the most likely value of $\pi$, so it minimizes a loss function that penalizes all misses equally. In the case of the beta posterior, it's just $\dfrac{\alpha^\prime - 1}{\alpha^\prime + \beta^\prime - 2}$ (for $\alpha^\prime, \beta^\prime > 1$). For our prior and data, we have $\dfrac{3 + 8 - 1}{(3 + k) + (15 + 150 - 8) - 2} \approx 0.060$.

### Example: Poisson Distribution

Suppose we collect $N$ random samples $x = \{x_1, x_2, ..., x_N\}$ and model each draw as a random variable $X \sim \text{Poisson}(\lambda)$. Find the posterior distribution of $\lambda$ for the gamma prior distribution. Hint: the gamma distribution is the conjugate prior for the Poisson likelihood.

$$
\begin{aligned}
\text{Poisson likelihood: } f(x \mid \lambda) &= \prod_{n = 1}^N \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \\
&= \displaystyle \left[ \frac{1}{\prod_{n = 1}^N x_n !} \right]e^{-N\lambda}\lambda^{\sum_{n = 1}^N x_n}
\end{aligned}
$$

$$
\text{Gamma prior: } f( \lambda; \alpha^*, \beta^*) = \frac{{\beta^*}^{\alpha^*}}{\Gamma(\alpha^*)} \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}
$$
To find the posterior, we multiply the likelihood times the prior and normalize. Because the gamma prior distribution is the conjugate prior for the Poisson likelihood, we know that the posterior will be a gamma distribution.

$$
\begin{aligned}
\text{Gamma posterior: } f( \lambda  \mid x) &= \frac{\left( \displaystyle \left[ \frac{1}{\prod_{n = 1}^N x_n !} \right]e^{-N\lambda}\lambda^{\sum_{n = 1}^N x_n}\right) \times \left( \left[ \frac{{\beta^*}^{\alpha^*}}{\Gamma(\alpha^*)} \right] \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}\right)}{C_1} \\
\end{aligned}
$$
Because $x$, $\alpha_*$, and $\beta$ are fixed, the terms in square brackets are constant, so we can safely consider those part of the normalizing constant.

$$
\begin{aligned}
&= \frac{\left( \displaystyle  e^{-N\lambda}\lambda^{\sum_{n = 1}^N x_n}\right) \times \left( \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}\right)}{C_2} \\
\end{aligned}
$$
Now we can collect the exponents with the same base.

$$
\begin{aligned}
&= \frac{\left( \lambda^{\alpha^* - 1} \times \lambda^{\sum_{n = 1}^N x_n}\right) \times \left( \displaystyle  e^{-N\lambda} \times e^{-\beta^*\lambda} \right)}{C_2} \\
&= \frac{\lambda^{ \overbrace{\left[ \alpha^* + \sum_{n = 1}^N x_n \right]}^{\alpha^\prime} - 1}  e^{-\overbrace{[\beta^* + N]}^{\beta^\prime}\lambda} }{C_2} \\
\end{aligned}
$$

We recognize this as *almost* a Gamma distribution with parameters $\alpha^\prime = \alpha^* +  \sum_{n = 1}^N x_n$ and $\beta^\prime = \beta^* + N$. Indeed, if $\frac{1}{C_2} = \frac{{\beta^\prime}^{\alpha^\prime}}{\Gamma(\alpha^{\prime})}$, then we have exactly a gamma distribution. 

$$
\begin{aligned}
&= \frac{{\beta^\prime}^{\alpha^\prime}}{\Gamma(\alpha^{\prime})} \lambda^{ \alpha^\prime - 1}  e^{-\beta^\prime\lambda}, \text{where } \alpha^\prime = \alpha^* +  \sum_{n = 1}^N x_n \text{ and } \beta^\prime = \beta^* + N
\end{aligned}
$$

Like the Bernoulli likelihood with the beta prior, the Poisson likelihood withe the gamma prior gives a nice result. We start with values parameters of the gamma distribution $\alpha = \alpha^*$ and $\beta + \beta^*$ so that the gamma prior distribution describes our prior beliefs about the parameters $\lambda$ of the Poisson distribution. Then we add the sum of the data $x$ to $\alpha^*$ and the number of samples $N$ to $\beta^*$ to obtain the parameters of the gamma posterior distribution.

The code below shows the posterior distribution 

```{r fig.height=3, fig.width=8, message=FALSE, warning=FALSE}
# set see to make reproducible
set.seed(1234)

# prior parameters
alpha_prior <- 3
beta_prior <- 3

# create an "unknown" value of lambda to estimate
lambda <- 2

# generate a data set
N <- 5  # number of samples
x <- rpois(N, lambda = lambda)
print(x)  # print the data set

# posterior parameters
alpha_posterior <- alpha_prior + sum(x)
beta_posterior <- beta_prior + N

# plot prior and posterior
gg_prior <- ggplot() + xlim(0, 5) + 
  stat_function(fun = dgamma, args = list(shape = alpha_prior, rate = beta_prior)) + 
  labs(title = "prior distribution", x = "lambda", y = "prior density")
gg_posterior <- ggplot() + xlim(0, 5) + 
  stat_function(fun = dgamma, args = list(shape = alpha_posterior, rate = beta_posterior)) + 
  labs(title = "posterior distribution", x = "lambda", y = "posterior density")
gg_prior + gg_posterior  # uses patchwork package

# posterior mean: alpha/beta
alpha_posterior/beta_posterior

# posterior median: no closed form, so simulate
post_sims <- rgamma(10000, alpha_posterior, beta_posterior)
median(post_sims)

# posterior mode: (alpha - 1)/beta for alpha > 1
(alpha_posterior - 1)/beta_posterior


```

### Remarks

Bayesian inference presents two difficulties. 

1. Choosing a prior. 
   a. It can be hard to actually construct a prior distribution. It's challenging when dealing with a single parameter. It becomes much more difficult when dealing with several or many parameters.
   a. Priors are subjective, so that one researcher's prior might not work for another. 
1. Computing the posterior. Especially for many-parameter problems and non-conjugate priors, computing the posterior can be nearly intractable.

However, there are several practical solutions to these difficulties.

1. Choosing a prior.
    a. We can use a "uninformative" or constant prior. Sometimes, we can use an improper prior that doesn't integrate to one, but places equal prior weight on all values. 
    a. We can use an extremely diffuse prior. For example, if we wanted to estimate the average height in a population in inches, we might use a normal distribution centered at zero with an SD of 10,000. This prior says: "The average height is about zero, give or take 10,000 inches or so."
    a. We can use an informative prior, but conduct careful robustness checks to assess whether the conclusions depend on the particular prior.
    a. We can use a weakly informative prior, that rules places meaningful prior weight on all the plausible values and little prior weight only on the most implausible values. As a guideline, you might create a weakly informative prior by doubling or tripling the SD of the informative prior.
1. Computing the posterior.
    a. While analytically deriving the posterior becomes intractable for most applied problems, it's relatively easy to *sample* from the posterior distribution for many models. 
    a. Algorithms like Gibbs samplers, MCMC, and HMC make this sampling procedure straightforward for a given model.
    a. Software such as Stan make sampling easy to set up and very fast. Post-processing R packages such as tidybayes make it each to work with the posterior simulations.
    

<!--chapter:end:02-02-mcmc.Rmd-->


## Exercises 

```{exercise, label="bayes-exponential"}
Suppose we collect $N$ random samples $x = \{x_1, x_2, ..., x_N\}$ and model each draw as a random variable $X \sim \text{exponential}(\lambda)$ with pdf $f(x_n | \lambda) = \lambda e^{-\lambda x_n}$. Find the posterior distribution of $\lambda$ for the gamma prior distribution. Hint: the gamma distribution is the conjugate prior for the exponential likelihood.
```

<details><summary>Hint</summary>
Use the Poisson example from above. Because they share a prior, the math works quite similarly.
</details>


<details><summary>Solution</summary>

$$
\begin{aligned}
\text{exponential likelihood: } f(x \mid \lambda) &= \prod_{n = 1}^N \lambda e^{-\lambda x_n} \\
&= \lambda^N e^{-\lambda \sum_{n = 1}^N x_n}
\end{aligned}
$$
$$
\text{Gamma prior: } f( \lambda; \alpha^*, \beta^*) = \frac{{\beta^*}^{\alpha^*}}{\Gamma(\alpha^*)} \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}
$$
$$
\begin{aligned}
\text{Gamma posterior: } f( \lambda  \mid x) &= \frac{\left(  \lambda^N e^{-\lambda \sum_{n = 1}^N x_n}\right) \times \left( \left[ \frac{{\beta^*}^{\alpha^*}}{\Gamma(\alpha^*)} \right] \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}\right)}{C_1} \\
&= \frac{\left(  \lambda^N e^{-\lambda \sum_{n = 1}^N x_n}\right) \times \left(  \lambda^{\alpha^* - 1} e^{-\beta^*\lambda}\right)}{C_2} \\
&= \frac{ \lambda^{ \overbrace{\left[ \alpha^* + N \right]}^{\alpha^\prime} - 1} e^{- \overbrace{\left[ \beta^* + \sum_{n = 1}^N x_n \right]}^{\beta^\prime} \lambda}}{C_2} \\
& =  \frac{{\beta^\prime}^{\alpha^\prime}}{\Gamma(\alpha^\prime)}  \lambda^{\alpha^\prime - 1} e^{-\beta^\prime\lambda}\text{ where } \alpha^\prime = \alpha^* +  N \text{ and } \beta^\prime = \beta^* + \sum_{n = 1}^N x_n
\end{aligned}
$$

</details>

```{exercise, label="govt-duration-bayes"}
You are a researcher interesting in government duration in parliamentary democracies. You decide to model duration as an exponential distribution. To estimate the parameter $\lambda$ of the exponential distribution, you collect data on the last five UK governments. 

- The first Johnson ministry lasted 142 days. 
- The second May ministry lasted 773 days.
- The first May ministry lasted 333 days.
- The second Cameron ministry lasted 432 days.
- The first Cameron ministry (Cameron-Clegg coalition) lasted 1,823 days.

1. Rescale the data to years--that helps with the interpretation.
1. Create three gamma prior distributions.
    a. One that describes your prior beliefs. 
    a. One that's weakly informative.
    a. One that's as uninformative as possible.
1. Use what you learned from Exercise \@ref(exr:bayes-exponential) to plot each prior and posterior.
1. For each posterior, compute the mean, median, and mode of $\lambda$. Interpret. Hint: $\lambda$ is a rate. If the durations are measured in years, then it's the failures per year. The expected duration in years is $\frac{1}{\lambda}$, but remember that $E \left( \frac{1}{\lambda}\right) \neq \frac{1} {E(\lambda)}$. If you want to find the posterior distribution of the expected duration (rather than the failures/year), then you can simulate many draws of $\lambda$ from the posterior and transform each draw into $\frac{1}{\lambda}$. The mean of the transformed draws is the posterior mean of the expected duration.
1. Assess the model. Do you think we have a good model? Hint: the exponential distribution is memoryless. Does that make sense in this appliation?
```

<details><summary>Solutions</summary>

```{r message=FALSE, warning=FALSE}
# load packages
library(tidyverse)
library(stringr)
library(kableExtra)

# set seed for reproducibility
set.seed(1234)

# choose informative  prior distribution
# - I expect govts to last, on avg, 3 years, so fail at a 
#   rate of lambda = 1/3 per year, give-or-take about 1/10.
# - I know that the mean of the gamma is a/b and the sd is 
#   sqrt{a/(b^2)}, so I set a/b = 1/3 and sqrt{a/(b^2)} = 1/10
#   and solve. You could also just experiment with different 
#   values
alpha_inf <- 100/9
beta_inf <-  3*alpha_inf

# plot informative prior
ggplot() + xlim(0, 1) +
  stat_function(fun = dgamma, args = list(shape = alpha_inf, rate = beta_inf)) + 
  labs(title = "prior distribution", x = "lambda; expected failures/year", y = "prior density")

# choose **weakly informative** prior distribution
# - For this, I repeated the same process, but doubled my
#   give-or-take from 1/10 to 1/5,
alpha_weak <- 25/9
beta_weak <- 3*alpha_weak

# plot weakly informative prior
ggplot() + xlim(0, 1) +
  stat_function(fun = dgamma, args = list(shape = alpha_weak, rate = beta_weak)) + 
  labs(title = "prior distribution", x = "lambda; expected failures/year", y = "prior density")

# choose flattest prior distribution
# - I just want to make this prior as close to uniform as possible.
# - the failure rate (failures/year) is *surely* between 0 and 100
#   (lambda = 100 means that 100 governments are failing per year), 
#   so I plot the prior from zero to 100--it's basically flat   
alpha_flat <- 1
beta_flat <- 0.01

# plot flattish prior
ggplot() + xlim(0, 100) + ylim(0, NA) + 
  stat_function(fun = dgamma, args = list(shape = alpha_flat, rate = beta_flat)) + 
  labs(title = "prior distribution", x = "lambda; expected failures/year", y = "prior density")

# data
x <- c(142, 773, 333, 432, 1823)/365  # rescale to years

# make a data frame with the posterior and prior parameters
posts <- data.frame(prior_type = c("Informative", 
                                   "Weakly Informative",
                                   "Flat-ish"),
                    alpha_prior = c(alpha_inf, 
                                    alpha_weak,
                                    alpha_flat),
                    beta_prior = c(beta_inf, 
                                    beta_weak,
                                    beta_flat)) %>%
  # add posterior parameters
  mutate(alpha_posterior = alpha_prior + length(x),
         beta_posterior = beta_prior + sum(x)) %>%
  # create one row per parameter
  pivot_longer(cols = alpha_prior:beta_posterior) %>%
  # separate parameter from distribution type
  separate(name, into = c("parameter", "distribution_type")) %>%
  # put parameters into separate columns
  pivot_wider(names_from = parameter, values_from = value) %>%
  mutate(distribution_type = str_to_title(distribution_type),
         distribution_type = factor(distribution_type, levels = c("Prior", "Posterior"))) %>%
  mutate(prior_type = factor(prior_type, levels = c("Informative", "Weakly Informative", "Flat-ish")))

# compute point estimates and make a table
point_estimates <- posts %>% 
  #filter(distribution_type == "posterior") %>%
  group_by(prior_type, distribution_type) %>%
  mutate(mean = alpha/beta,
         median = median(rgamma(100000, alpha, beta)),
         mode = (alpha - 1)/beta,
         mean_expected_duration = mean(1/rgamma(100000, shape = alpha, rate = beta))) 

point_estimates %>%
  select(-alpha, -beta) %>%
  arrange(distribution_type, prior_type) %>%
  rename(`Prior` = prior_type, 
         `Distribution` = distribution_type,
         `Mean of lambda` = mean,
         `Median of lambda` = median,
         `Mode of lambda` = mode,
         `Mean of 1/lambda` = mean_expected_duration) %>%
  kable(format = "markdown", digits = 2)

# plot distributions
gg_posts <- posts %>%
  # add in lambda values for which to compute the prior and posterior density
  full_join(data_frame(lambda = seq(0, 2, length.out = 100)), 
            by = character()) %>%
  # compute the posterior and prior density for each lambda
  mutate(density = dgamma(lambda, shape = alpha, rate = beta))

ggplot(gg_posts, aes(x = lambda, y = density, 
                  color = prior_type, 
                  linetype = distribution_type)) + 
  geom_line()

```

</details>

<!--chapter:end:02-99-exercises.Rmd-->

