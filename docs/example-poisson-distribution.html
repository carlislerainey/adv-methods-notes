<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.3 Example: Poisson Distribution | Inference in Six Lessons</title>
  <meta name="description" content="Lecture notes covering the basics concepts of statistical inference for first-year political science PhD students." />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="2.3 Example: Poisson Distribution | Inference in Six Lessons" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes covering the basics concepts of statistical inference for first-year political science PhD students." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.3 Example: Poisson Distribution | Inference in Six Lessons" />
  
  <meta name="twitter:description" content="Lecture notes covering the basics concepts of statistical inference for first-year political science PhD students." />
  

<meta name="author" content="Carlisle Rainey" />


<meta name="date" content="2022-08-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="example-bernoulli-distribution.html"/>
<link rel="next" href="deriving-point-estimates.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Inference<span></span></a></li>
<li class="chapter" data-level="2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>2</b> Maximum Likelihood<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="mechanics.html"><a href="mechanics.html"><i class="fa fa-check"></i><b>2.1</b> Mechanics<span></span></a></li>
<li class="chapter" data-level="2.2" data-path="example-bernoulli-distribution.html"><a href="example-bernoulli-distribution.html"><i class="fa fa-check"></i><b>2.2</b> Example: Bernoulli Distribution<span></span></a></li>
<li class="chapter" data-level="2.3" data-path="example-poisson-distribution.html"><a href="example-poisson-distribution.html"><i class="fa fa-check"></i><b>2.3</b> Example: Poisson Distribution<span></span></a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="example-poisson-distribution.html"><a href="example-poisson-distribution.html#example-german-tank-problem"><i class="fa fa-check"></i><b>2.3.1</b> Example: German Tank Problem<span></span></a></li>
<li class="chapter" data-level="2.3.2" data-path="example-poisson-distribution.html"><a href="example-poisson-distribution.html#example-poisson-distribution-1"><i class="fa fa-check"></i><b>2.3.2</b> Example: Poisson Distribution<span></span></a></li>
<li class="chapter" data-level="2.3.3" data-path="example-poisson-distribution.html"><a href="example-poisson-distribution.html#remarks"><i class="fa fa-check"></i><b>2.3.3</b> Remarks<span></span></a></li>
<li class="chapter" data-level="2.3.4" data-path="example-poisson-distribution.html"><a href="example-poisson-distribution.html#exercises"><i class="fa fa-check"></i><b>2.3.4</b> Exercises<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="deriving-point-estimates.html"><a href="deriving-point-estimates.html"><i class="fa fa-check"></i><b>3</b> Deriving Point Estimates<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>3.1</b> Bayesian Inference<span></span></a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#mechanics-1"><i class="fa fa-check"></i><b>3.1.1</b> Mechanics<span></span></a></li>
<li class="chapter" data-level="3.1.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#example-poisson-distribution-2"><i class="fa fa-check"></i><b>3.1.2</b> Example: Poisson Distribution<span></span></a></li>
<li class="chapter" data-level="3.1.3" data-path="bayesian-inference.html"><a href="bayesian-inference.html#remarks-1"><i class="fa fa-check"></i><b>3.1.3</b> Remarks<span></span></a></li>
<li class="chapter" data-level="3.1.4" data-path="bayesian-inference.html"><a href="bayesian-inference.html#exercises-1"><i class="fa fa-check"></i><b>3.1.4</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="method-of-moments.html"><a href="method-of-moments.html"><i class="fa fa-check"></i><b>3.2</b> Method of Moments<span></span></a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="method-of-moments.html"><a href="method-of-moments.html#mechanics-2"><i class="fa fa-check"></i><b>3.2.1</b> Mechanics<span></span></a></li>
<li class="chapter" data-level="3.2.2" data-path="method-of-moments.html"><a href="method-of-moments.html#example-gamma-distribution"><i class="fa fa-check"></i><b>3.2.2</b> Example: Gamma Distribution<span></span></a></li>
<li class="chapter" data-level="3.2.3" data-path="method-of-moments.html"><a href="method-of-moments.html#example-toothpaste-cap-problem"><i class="fa fa-check"></i><b>3.2.3</b> Example: Toothpaste Cap Problem<span></span></a></li>
<li class="chapter" data-level="3.2.4" data-path="method-of-moments.html"><a href="method-of-moments.html#example-population-average"><i class="fa fa-check"></i><b>3.2.4</b> Example: Population Average<span></span></a></li>
<li class="chapter" data-level="3.2.5" data-path="method-of-moments.html"><a href="method-of-moments.html#example-population-average-and-sd"><i class="fa fa-check"></i><b>3.2.5</b> Example: Population Average and SD<span></span></a></li>
<li class="chapter" data-level="3.2.6" data-path="method-of-moments.html"><a href="method-of-moments.html#example-german-tank-problem-1"><i class="fa fa-check"></i><b>3.2.6</b> Example: German Tank Problem<span></span></a></li>
<li class="chapter" data-level="3.2.7" data-path="method-of-moments.html"><a href="method-of-moments.html#remarks-2"><i class="fa fa-check"></i><b>3.2.7</b> Remarks<span></span></a></li>
<li class="chapter" data-level="3.2.8" data-path="method-of-moments.html"><a href="method-of-moments.html#exercises-2"><i class="fa fa-check"></i><b>3.2.8</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="maximum-likelihood-1.html"><a href="maximum-likelihood-1.html"><i class="fa fa-check"></i><b>3.3</b> Maximum Likelihood<span></span></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="maximum-likelihood-1.html"><a href="maximum-likelihood-1.html#mechanics-3"><i class="fa fa-check"></i><b>3.3.1</b> Mechanics<span></span></a></li>
<li class="chapter" data-level="3.3.2" data-path="maximum-likelihood-1.html"><a href="maximum-likelihood-1.html#example-toothpaste-cap-problem-1"><i class="fa fa-check"></i><b>3.3.2</b> Example: Toothpaste Cap Problem<span></span></a></li>
<li class="chapter" data-level="3.3.3" data-path="maximum-likelihood-1.html"><a href="maximum-likelihood-1.html#example-german-tank-problem-2"><i class="fa fa-check"></i><b>3.3.3</b> Example: German Tank Problem<span></span></a></li>
<li class="chapter" data-level="3.3.4" data-path="maximum-likelihood-1.html"><a href="maximum-likelihood-1.html#example-poisson-distribution-3"><i class="fa fa-check"></i><b>3.3.4</b> Example: Poisson Distribution<span></span></a></li>
<li class="chapter" data-level="3.3.5" data-path="maximum-likelihood-1.html"><a href="maximum-likelihood-1.html#remarks-3"><i class="fa fa-check"></i><b>3.3.5</b> Remarks<span></span></a></li>
<li class="chapter" data-level="3.3.6" data-path="maximum-likelihood-1.html"><a href="maximum-likelihood-1.html#exercises-3"><i class="fa fa-check"></i><b>3.3.6</b> Exercises<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="evaluating-point-estimates.html"><a href="evaluating-point-estimates.html"><i class="fa fa-check"></i><b>4</b> Evaluating Point Estimates<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="bias.html"><a href="bias.html"><i class="fa fa-check"></i><b>4.1</b> Bias<span></span></a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="bias.html"><a href="bias.html#example-sample-average"><i class="fa fa-check"></i><b>4.1.1</b> Example: Sample Average<span></span></a></li>
<li class="chapter" data-level="4.1.2" data-path="bias.html"><a href="bias.html#example-poisson-distribution-4"><i class="fa fa-check"></i><b>4.1.2</b> Example: Poisson Distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="consistency.html"><a href="consistency.html"><i class="fa fa-check"></i><b>4.2</b> Consistency<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="mvue-or-bue.html"><a href="mvue-or-bue.html"><i class="fa fa-check"></i><b>4.3</b> MVUE or BUE<span></span></a></li>
<li class="chapter" data-level="4.4" data-path="evaluating-point-estimates-exercises.html"><a href="evaluating-point-estimates-exercises.html"><i class="fa fa-check"></i><b>4.4</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="deriving-hypothesis-test.html"><a href="deriving-hypothesis-test.html"><i class="fa fa-check"></i><b>5</b> Deriving Hypothesis Test<span></span></a>
<ul>
<li class="chapter" data-level="5.1" data-path="the-null-and-alternative-hypothesis.html"><a href="the-null-and-alternative-hypothesis.html"><i class="fa fa-check"></i><b>5.1</b> The Null (and Alternative) Hypothesis<span></span></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="the-null-and-alternative-hypothesis.html"><a href="the-null-and-alternative-hypothesis.html#the-most-common-null-hypotheses"><i class="fa fa-check"></i><b>5.1.1</b> The Most Common Null Hypotheses<span></span></a></li>
<li class="chapter" data-level="5.1.2" data-path="the-null-and-alternative-hypothesis.html"><a href="the-null-and-alternative-hypothesis.html#errors"><i class="fa fa-check"></i><b>5.1.2</b> Errors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="test-statistics.html"><a href="test-statistics.html"><i class="fa fa-check"></i><b>5.2</b> Test Statistics<span></span></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="test-statistics.html"><a href="test-statistics.html#power-function"><i class="fa fa-check"></i><b>5.2.1</b> Power Function<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="test-statistics.html"><a href="test-statistics.html#the-likelihood-ratio-test"><i class="fa fa-check"></i><b>5.2.2</b> The Likelihood Ratio Test<span></span></a></li>
<li class="chapter" data-level="5.2.3" data-path="test-statistics.html"><a href="test-statistics.html#wald-test"><i class="fa fa-check"></i><b>5.2.3</b> Wald Test<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="evaluating-tests.html"><a href="evaluating-tests.html"><i class="fa fa-check"></i><b>5.3</b> Evaluating Tests<span></span></a></li>
<li class="chapter" data-level="5.4" data-path="size-of-the-lrt.html"><a href="size-of-the-lrt.html"><i class="fa fa-check"></i><b>5.4</b> Size of the LRT<span></span></a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="size-of-the-lrt.html"><a href="size-of-the-lrt.html#p-values"><i class="fa fa-check"></i><b>5.4.1</b> <em>p</em>-Values<span></span></a></li>
<li class="chapter" data-level="5.4.2" data-path="size-of-the-lrt.html"><a href="size-of-the-lrt.html#size-of-the-wald-test"><i class="fa fa-check"></i><b>5.4.2</b> Size of the Wald Test<span></span></a></li>
<li class="chapter" data-level="5.4.3" data-path="size-of-the-lrt.html"><a href="size-of-the-lrt.html#size-of-the"><i class="fa fa-check"></i><b>5.4.3</b> Size of the<span></span></a></li>
<li class="chapter" data-level="5.4.4" data-path="size-of-the-lrt.html"><a href="size-of-the-lrt.html#bayesian-tests"><i class="fa fa-check"></i><b>5.4.4</b> Bayesian Tests<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="appendix-code-for-beta-prior.html"><a href="appendix-code-for-beta-prior.html"><i class="fa fa-check"></i><b>6</b> Appendix: Code for Beta Prior<span></span></a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inference in Six Lessons</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="example-poisson-distribution" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Example: Poisson Distribution<a href="example-poisson-distribution.html#example-poisson-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we collect <span class="math inline">\(N\)</span> random samples <span class="math inline">\(x = \{x_1, x_2, ..., x_N\}\)</span> and model each draw as a random variable <span class="math inline">\(X \sim \text{Poisson}(\lambda)\)</span>. Find the ML estimator of <span class="math inline">\(\lambda\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\text{Poisson likelihood: } f(x \mid \lambda) &amp;= \prod_{n = 1}^N \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \\
L(\lambda) &amp;= \prod_{n = 1}^N \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \\
\log L(\lambda) &amp;= \sum_{n = 1}^N \log \left[ \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \right]\\
&amp;= \sum_{n = 1}^N \left[ x_n \log \lambda + (-\lambda) \log e - \log x_n! \right]\\
&amp;= \log \lambda \left[ \sum_{n = 1}^N x_n \right]  -N\lambda + \sum_{n = 1}^N \log (x_n!) \\
\end{aligned}
\]</span></p>
<p>To find the ML estimator, we find <span class="math inline">\(\hat{\lambda}\)</span> that maximizes <span class="math inline">\(\log L\)</span>. In this case, the analytical optimum is easy.</p>
<p><span class="math display">\[
\begin{aligned}
\frac{d \log L}{d\hat{\lambda}} = \frac{1}{\hat{\lambda}} \left[ \sum_{n = 1}^N x_n \right] - N &amp;= 0\\
\frac{1}{\hat{\lambda}} \left[ \sum_{n = 1}^N x_n \right] &amp;= N \\
\left[ \sum_{n = 1}^N x_n \right] &amp;= N \hat{\lambda} \\
\hat{\lambda} &amp;= \frac{ \sum_{n = 1}^N x_n }{N} = \text{avg}(x)  \\
\end{aligned}
\]</span>
The ML estimator for the Poisson distribution is just the average of the samples.</p>
<div id="example-german-tank-problem" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Example: German Tank Problem<a href="example-poisson-distribution.html#example-german-tank-problem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The German tank problem is an excellent example of an ML estimator because one can think through the logic intuitively rather than mathematically.</p>
<p>Recall that the Allies observe <span class="math inline">\(N\)</span> serial numbers of German tanks. By treating these serial numbers as samples without replacement from a set of sequential serial numbers <span class="math inline">\(S = \{1, 2, ..., \nu\}\)</span>, they can estimate the total number of German tanks <span class="math inline">\(\nu\)</span>.</p>
<p>Because we’re sampling <em>without</em> replacement, the likelihood is quite complicated.</p>
<p><span class="math display">\[
f(x \mid \nu) = f(x_1) f(x_2 \mid x_1) ... f(x_N | x_{N - 1}, ..., x_2, x_1), \\
\text{where } x_i \neq x_j \text{ for } i \neq j.
\]</span></p>
<p>Remember that <span class="math inline">\(\nu\)</span> is the total number of tanks. So the chance that we observe <span class="math inline">\(x_1\)</span> first is <span class="math inline">\(\frac{1}{\nu}\)</span>. The chance we observe <span class="math inline">\(x_2\)</span> second, given that we observe <span class="math inline">\(x_1\)</span> first is <span class="math inline">\(\frac{1}{\nu - 1}\)</span>. The chance we observe <span class="math inline">\(x_N\)</span> <span class="math inline">\(N\)</span>th is <span class="math inline">\(\frac{1}{\nu - (N - 1)}\)</span>.</p>
<p><span class="math display">\[
L(\nu) = \frac{1}{\nu} \times \frac{1}{\nu - 1} \times ... \times \frac{1}{\nu - (N - 1)}
\]</span>
It’s clear, then, that in order to make <span class="math inline">\(L\)</span> as large as possible, we need to make <span class="math inline">\(\nu\)</span> as small as possible. However, notice that <span class="math inline">\(\nu\)</span> cannot be less than <span class="math inline">\(\max \{x_1, ..., x_N\}\)</span> (i.e., the largest serial number must be greater than or equal to the largest <em>observed</em> serial number).</p>
<p>So what’s the smallest value of <span class="math inline">\(\nu\)</span> that satisfies <span class="math inline">\(\nu \geq \max \{x_1, ..., x_N\}\)</span>? Of course it’s <span class="math inline">\(\hat{\nu} = \max \{x_1, ..., x_N\}\)</span>.</p>
<p>To illustrate, I simulate the same five data sets from above and compute the MM and ML estimates. Take a look at the five data sets and five estimates. Would you say that one estimator seems better? Can the ML estimate ever be too large? Can the MM estimate ever be too small?</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="example-poisson-distribution.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the estimators</span></span>
<span id="cb1-2"><a href="example-poisson-distribution.html#cb1-2" aria-hidden="true" tabindex="-1"></a>calc_nu_hat_mm <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb1-3"><a href="example-poisson-distribution.html#cb1-3" aria-hidden="true" tabindex="-1"></a>  N <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb1-4"><a href="example-poisson-distribution.html#cb1-4" aria-hidden="true" tabindex="-1"></a>  sum_x <span class="ot">&lt;-</span> <span class="fu">sum</span>(x)</span>
<span id="cb1-5"><a href="example-poisson-distribution.html#cb1-5" aria-hidden="true" tabindex="-1"></a>  nu_hat <span class="ot">&lt;-</span> ((<span class="dv">2</span> <span class="sc">/</span> N) <span class="sc">*</span> sum_x) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb1-6"><a href="example-poisson-distribution.html#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(nu_hat)</span>
<span id="cb1-7"><a href="example-poisson-distribution.html#cb1-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-8"><a href="example-poisson-distribution.html#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># the estimators</span></span>
<span id="cb1-9"><a href="example-poisson-distribution.html#cb1-9" aria-hidden="true" tabindex="-1"></a>calc_nu_hat_ml <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb1-10"><a href="example-poisson-distribution.html#cb1-10" aria-hidden="true" tabindex="-1"></a>  nu_hat <span class="ot">&lt;-</span> <span class="fu">max</span>(x)</span>
<span id="cb1-11"><a href="example-poisson-distribution.html#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(nu_hat)</span>
<span id="cb1-12"><a href="example-poisson-distribution.html#cb1-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-13"><a href="example-poisson-distribution.html#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="example-poisson-distribution.html#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># simulation parameters</span></span>
<span id="cb1-15"><a href="example-poisson-distribution.html#cb1-15" aria-hidden="true" tabindex="-1"></a>n_sims <span class="ot">&lt;-</span> <span class="dv">5</span>  <span class="co"># the number of repeated samples</span></span>
<span id="cb1-16"><a href="example-poisson-distribution.html#cb1-16" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">5</span>       <span class="co"># the number of observations in each sample</span></span>
<span id="cb1-17"><a href="example-poisson-distribution.html#cb1-17" aria-hidden="true" tabindex="-1"></a>nu <span class="ot">&lt;-</span> <span class="dv">100</span>    <span class="co"># the true value of nu</span></span>
<span id="cb1-18"><a href="example-poisson-distribution.html#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="example-poisson-distribution.html#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># do the simulation</span></span>
<span id="cb1-20"><a href="example-poisson-distribution.html#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb1-21"><a href="example-poisson-distribution.html#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_sims) {</span>
<span id="cb1-22"><a href="example-poisson-distribution.html#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># take the ith sample</span></span>
<span id="cb1-23"><a href="example-poisson-distribution.html#cb1-23" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>nu, <span class="at">size =</span> N, <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb1-24"><a href="example-poisson-distribution.html#cb1-24" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">sort</span>(x)  <span class="co"># sort x for convenience</span></span>
<span id="cb1-25"><a href="example-poisson-distribution.html#cb1-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute the estimates</span></span>
<span id="cb1-26"><a href="example-poisson-distribution.html#cb1-26" aria-hidden="true" tabindex="-1"></a>  nu_hat_mm <span class="ot">&lt;-</span> <span class="fu">calc_nu_hat_mm</span>(x)</span>
<span id="cb1-27"><a href="example-poisson-distribution.html#cb1-27" aria-hidden="true" tabindex="-1"></a>  nu_hat_ml <span class="ot">&lt;-</span> <span class="fu">calc_nu_hat_ml</span>(x)</span>
<span id="cb1-28"><a href="example-poisson-distribution.html#cb1-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print the results</span></span>
<span id="cb1-29"><a href="example-poisson-distribution.html#cb1-29" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span> <span class="fu">paste0</span>(stringr<span class="sc">::</span><span class="fu">str_pad</span>(x, <span class="dv">3</span>, <span class="at">pad =</span> <span class="st">&quot;0&quot;</span>), <span class="at">collapse =</span> <span class="st">&quot;, &quot;</span>)</span>
<span id="cb1-30"><a href="example-poisson-distribution.html#cb1-30" aria-hidden="true" tabindex="-1"></a>  mm_estimate <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;MM estimate = &quot;</span>, <span class="fu">round</span>(nu_hat_mm, <span class="dv">2</span>))</span>
<span id="cb1-31"><a href="example-poisson-distribution.html#cb1-31" aria-hidden="true" tabindex="-1"></a>    ml_estimate <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;ML estimate = &quot;</span>, <span class="fu">round</span>(nu_hat_ml, <span class="dv">2</span>))</span>
<span id="cb1-32"><a href="example-poisson-distribution.html#cb1-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;Sim. #&quot;</span>, i, <span class="st">&quot;: &quot;</span>, data, <span class="st">&quot; --&gt; &quot;</span>, ml_estimate, <span class="st">&quot;; &quot;</span>, mm_estimate, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb1-33"><a href="example-poisson-distribution.html#cb1-33" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## Sim. #1: 014, 051, 080, 090, 092 --&gt; ML estimate = 92; MM estimate = 129.8
## Sim. #2: 024, 058, 075, 093, 096 --&gt; ML estimate = 96; MM estimate = 137.4
## Sim. #3: 002, 038, 075, 086, 088 --&gt; ML estimate = 88; MM estimate = 114.6
## Sim. #4: 010, 032, 040, 081, 094 --&gt; ML estimate = 94; MM estimate = 101.8
## Sim. #5: 001, 030, 038, 039, 076 --&gt; ML estimate = 76; MM estimate = 72.6</code></pre>
</div>
<div id="example-poisson-distribution-1" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Example: Poisson Distribution<a href="example-poisson-distribution.html#example-poisson-distribution-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we collect <span class="math inline">\(N\)</span> random samples <span class="math inline">\(x = \{x_1, x_2, ..., x_N\}\)</span> and model each draw as a random variable <span class="math inline">\(X \sim \text{Poisson}(\lambda)\)</span>. Find the ML estimator of <span class="math inline">\(\lambda\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\text{Poisson likelihood: } f(x \mid \lambda) &amp;= \prod_{n = 1}^N \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \\
L(\lambda) &amp;= \prod_{n = 1}^N \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \\
\log L(\lambda) &amp;= \sum_{n = 1}^N \log \left[ \frac{\lambda^{x_n} e^{-\lambda}}{x_n!} \right]\\
&amp;= \sum_{n = 1}^N \left[ x_n \log \lambda + (-\lambda) \log e - \log x_n! \right]\\
&amp;= \log \lambda \left[ \sum_{n = 1}^N x_n \right]  -N\lambda + \sum_{n = 1}^N \log (x_n!) \\
\end{aligned}
\]</span>
To find the ML estimator, we find <span class="math inline">\(\hat{\lambda}\)</span> that maximizes <span class="math inline">\(\log L\)</span>. In this case, the analytical optimum is easy.</p>
<p><span class="math display">\[
\begin{aligned}
\frac{d \log L}{d\hat{\lambda}} = \frac{1}{\hat{\lambda}} \left[ \sum_{n = 1}^N x_n \right] - N &amp;= 0\\
\frac{1}{\hat{\lambda}} \left[ \sum_{n = 1}^N x_n \right] &amp;= N \\
\left[ \sum_{n = 1}^N x_n \right] &amp;= N \hat{\lambda} \\
\hat{\lambda} &amp;= \frac{ \sum_{n = 1}^N x_n }{N} = \text{avg}(x)  \\
\end{aligned}
\]</span>
The ML estimator for the Poisson distribution is just the average of the samples.</p>
</div>
<div id="remarks" class="section level3 hasAnchor" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> Remarks<a href="example-poisson-distribution.html#remarks" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The ML estimator is extremely common in political science because they are general, fast, and work extremely well. Lots of models that you’ve heard of, such as logistic regression, are estimated with ML.</p>
<p>We can even obtain ML estimates for the linear regression model. We assume that the observed data are samples from a normal distribution with mean <span class="math inline">\(\mu_n = \alpha + \beta x_n\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. For this model, the least-squares estimate that we learned earlier is also the ML estimate.</p>
</div>
<div id="exercises" class="section level3 hasAnchor" number="2.3.4">
<h3><span class="header-section-number">2.3.4</span> Exercises<a href="example-poisson-distribution.html#exercises" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="exercise">
<p><span id="exr:ml-exponential" class="exercise"><strong>Exercise 2.1  </strong></span>Suppose we collect <span class="math inline">\(N\)</span> random samples <span class="math inline">\(x = \{x_1, x_2, ..., x_N\}\)</span> and model each draw as a random variable <span class="math inline">\(X \sim \text{exponential}(\lambda)\)</span> with pdf <span class="math inline">\(f(x_n | \lambda) = \lambda e^{-\lambda x_n}\)</span>. Find the maximum estimator of <span class="math inline">\(\lambda\)</span>.</p>
</div>
<details>
<summary>
Solution
</summary>
The math follows the Poisson example closely. However, the solution is the inverse–<span class="math inline">\(\hat{\lambda} = \frac{N}{\sum_{n = 1}^N x_n } = \frac{1}{\text{avg}(x)}\)</span>.
</details>
<div class="exercise">
<p><span id="exr:ml-govt-duration" class="exercise"><strong>Exercise 2.2  </strong></span>Model the data from Exercise <a href="#exr:govt-duration-bayes"><strong>??</strong></a> as draws from an exponential distribution with rate parameter <span class="math inline">\(\lambda\)</span>. Use the maximum estimator from Exercise <a href="example-poisson-distribution.html#exr:ml-exponential">2.1</a> to estimate <span class="math inline">\(\lambda\)</span>.</p>
<p>What if you want to estimate the mean duration <span class="math inline">\(\mu = \frac{1}{\lambda}\)</span> rather than the failure rate <span class="math inline">\(\lambda\)</span>? Can you just use <span class="math inline">\(\hat{\mu} = \frac{1}{\hat{\lambda}}\)</span>?</p>
</div>
<details>
<summary>
Solution
</summary>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="example-poisson-distribution.html#cb3-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">142</span>, <span class="dv">773</span>, <span class="dv">333</span>, <span class="dv">432</span>, <span class="dv">1823</span>)<span class="sc">/</span><span class="dv">365</span>  <span class="co"># rescale to years</span></span>
<span id="cb3-2"><a href="example-poisson-distribution.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">/</span><span class="fu">mean</span>(x)  <span class="co"># ml estimator of lambda</span></span></code></pre></div>
<pre><code>## [1] 0.520982</code></pre>
Like MM estimators, ML estimators are invariant under transformation, though this is not as obvious as it is for MM estimators. For this problem, <span class="math inline">\(\hat{\mu} = \frac{1}{\hat{\lambda}}\)</span>.
</details>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="example-bernoulli-distribution.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="deriving-point-estimates.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
