<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.2 Bernoulli Model | Statistical Modeling: A Tools Approach</title>
  <meta name="description" content="Lecture notes covering the key tools of regression modeling in political science." />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="3.2 Bernoulli Model | Statistical Modeling: A Tools Approach" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes covering the key tools of regression modeling in political science." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.2 Bernoulli Model | Statistical Modeling: A Tools Approach" />
  
  <meta name="twitter:description" content="Lecture notes covering the key tools of regression modeling in political science." />
  

<meta name="author" content="Carlisle Rainey" />


<meta name="date" content="2022-09-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="review-the-normal-model.html"/>
<link rel="next" href="poisson-model.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Political Methodology</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Week 1: Maximum Likelihood<span></span></a>
<ul>
<li class="chapter" data-level="1.1" data-path="class-agenda.html"><a href="class-agenda.html"><i class="fa fa-check"></i><b>1.1</b> Class agenda<span></span></a></li>
<li class="chapter" data-level="1.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>1.2</b> Maximum Likelihood<span></span></a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#example-bernoulli-distribution"><i class="fa fa-check"></i><b>1.2.1</b> Example: Bernoulli Distribution<span></span></a></li>
<li class="chapter" data-level="1.2.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#example-poisson-distribution"><i class="fa fa-check"></i><b>1.2.2</b> Example: Poisson Distribution<span></span></a></li>
<li class="chapter" data-level="1.2.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#remarks"><i class="fa fa-check"></i><b>1.2.3</b> Remarks<span></span></a></li>
<li class="chapter" data-level="1.2.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#example-beta-distribution"><i class="fa fa-check"></i><b>1.2.4</b> Example: Beta Distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="the-invariance-property.html"><a href="the-invariance-property.html"><i class="fa fa-check"></i><b>1.3</b> The Invariance Property<span></span></a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="the-invariance-property.html"><a href="the-invariance-property.html#example-bernoulli-odds"><i class="fa fa-check"></i><b>1.3.1</b> Example: Bernoulli Odds<span></span></a></li>
<li class="chapter" data-level="1.3.2" data-path="the-invariance-property.html"><a href="the-invariance-property.html#example-poisson-sd"><i class="fa fa-check"></i><b>1.3.2</b> Example: Poisson SD<span></span></a></li>
<li class="chapter" data-level="1.3.3" data-path="the-invariance-property.html"><a href="the-invariance-property.html#example-beta-mean-and-variance"><i class="fa fa-check"></i><b>1.3.3</b> Example: Beta Mean and Variance<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="the-parametric-bootstrap.html"><a href="the-parametric-bootstrap.html"><i class="fa fa-check"></i><b>1.4</b> The Parametric Bootstrap<span></span></a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="the-parametric-bootstrap.html"><a href="the-parametric-bootstrap.html#example-toothpaste-cap-problm"><i class="fa fa-check"></i><b>1.4.1</b> Example: Toothpaste Cap Problm<span></span></a></li>
<li class="chapter" data-level="1.4.2" data-path="the-parametric-bootstrap.html"><a href="the-parametric-bootstrap.html#example-beta-distribution-1"><i class="fa fa-check"></i><b>1.4.2</b> Example: Beta Distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="sampling-distribution.html"><a href="sampling-distribution.html"><i class="fa fa-check"></i><b>1.5</b> Sampling Distribution<span></span></a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="sampling-distribution.html"><a href="sampling-distribution.html#example-the-toothpaste-cap-problem"><i class="fa fa-check"></i><b>1.5.1</b> Example: The Toothpaste Cap Problem<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="bias.html"><a href="bias.html"><i class="fa fa-check"></i><b>1.6</b> Bias<span></span></a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="bias.html"><a href="bias.html#example-bernoulli-distribution-1"><i class="fa fa-check"></i><b>1.6.1</b> Example: Bernoulli Distribution<span></span></a></li>
<li class="chapter" data-level="1.6.2" data-path="bias.html"><a href="bias.html#example-poisson-distribution-1"><i class="fa fa-check"></i><b>1.6.2</b> Example: Poisson Distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="consistency.html"><a href="consistency.html"><i class="fa fa-check"></i><b>1.7</b> Consistency<span></span></a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="consistency.html"><a href="consistency.html#example-illustrative"><i class="fa fa-check"></i><b>1.7.1</b> Example: Illustrative<span></span></a></li>
<li class="chapter" data-level="1.7.2" data-path="consistency.html"><a href="consistency.html#example-bernoulli-odds-1"><i class="fa fa-check"></i><b>1.7.2</b> Example: Bernoulli Odds<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="predictive-distribution.html"><a href="predictive-distribution.html"><i class="fa fa-check"></i><b>1.8</b> Predictive Distribution<span></span></a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="predictive-distribution.html"><a href="predictive-distribution.html#example-poisson-distribution-2"><i class="fa fa-check"></i><b>1.8.1</b> Example: Poisson Distribution<span></span></a></li>
<li class="chapter" data-level="1.8.2" data-path="predictive-distribution.html"><a href="predictive-distribution.html#example-beta-distribution-2"><i class="fa fa-check"></i><b>1.8.2</b> Example: Beta Distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.9</b> Exercises<span></span></a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="exercises.html"><a href="exercises.html#questions-about-the-exponential-distribution"><i class="fa fa-check"></i><b>1.9.1</b> Questions About the Exponential Distribution<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="week-2-bayesian-inference.html"><a href="week-2-bayesian-inference.html"><i class="fa fa-check"></i><b>2</b> Week 2: Bayesian Inference<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>2.1</b> Bayesian Inference<span></span></a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#mechanics"><i class="fa fa-check"></i><b>2.1.1</b> Mechanics<span></span></a></li>
<li class="chapter" data-level="2.1.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#posterior-summaries"><i class="fa fa-check"></i><b>2.1.2</b> Posterior Summaries<span></span></a></li>
<li class="chapter" data-level="2.1.3" data-path="bayesian-inference.html"><a href="bayesian-inference.html#posterior-simulation"><i class="fa fa-check"></i><b>2.1.3</b> Posterior Simulation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="example-bernoulli.html"><a href="example-bernoulli.html"><i class="fa fa-check"></i><b>2.2</b> Example: Bernoulli<span></span></a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="example-bernoulli.html"><a href="example-bernoulli.html#likelihood"><i class="fa fa-check"></i><b>2.2.1</b> The Likelihood<span></span></a></li>
<li class="chapter" data-level="2.2.2" data-path="example-bernoulli.html"><a href="example-bernoulli.html#the-prior"><i class="fa fa-check"></i><b>2.2.2</b> The Prior<span></span></a></li>
<li class="chapter" data-level="2.2.3" data-path="example-bernoulli.html"><a href="example-bernoulli.html#the-posterior"><i class="fa fa-check"></i><b>2.2.3</b> The Posterior<span></span></a></li>
<li class="chapter" data-level="2.2.4" data-path="example-bernoulli.html"><a href="example-bernoulli.html#point-estimates"><i class="fa fa-check"></i><b>2.2.4</b> Point Estimates<span></span></a></li>
<li class="chapter" data-level="2.2.5" data-path="example-bernoulli.html"><a href="example-bernoulli.html#credible-interval"><i class="fa fa-check"></i><b>2.2.5</b> Credible Interval<span></span></a></li>
<li class="chapter" data-level="2.2.6" data-path="example-bernoulli.html"><a href="example-bernoulli.html#simulation"><i class="fa fa-check"></i><b>2.2.6</b> Simulation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="example-poisson-distribution-3.html"><a href="example-poisson-distribution-3.html"><i class="fa fa-check"></i><b>2.3</b> Example: Poisson Distribution<span></span></a></li>
<li class="chapter" data-level="2.4" data-path="remarks-1.html"><a href="remarks-1.html"><i class="fa fa-check"></i><b>2.4</b> Remarks<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="week-3-adding-predictors.html"><a href="week-3-adding-predictors.html"><i class="fa fa-check"></i><b>3</b> Week 3: Adding Predictors<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="review-the-normal-model.html"><a href="review-the-normal-model.html"><i class="fa fa-check"></i><b>3.1</b> Review: The Normal Model<span></span></a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="review-the-normal-model.html"><a href="review-the-normal-model.html#distribution"><i class="fa fa-check"></i><b>3.1.1</b> Distribution<span></span></a></li>
<li class="chapter" data-level="3.1.2" data-path="review-the-normal-model.html"><a href="review-the-normal-model.html#linear-predictor"><i class="fa fa-check"></i><b>3.1.2</b> Linear Predictor<span></span></a></li>
<li class="chapter" data-level="3.1.3" data-path="review-the-normal-model.html"><a href="review-the-normal-model.html#fitting-the-normal-linear-model"><i class="fa fa-check"></i><b>3.1.3</b> Fitting the Normal-Linear Model<span></span></a></li>
<li class="chapter" data-level="3.1.4" data-path="review-the-normal-model.html"><a href="review-the-normal-model.html#applied-example"><i class="fa fa-check"></i><b>3.1.4</b> Applied Example<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="bernoulli-model.html"><a href="bernoulli-model.html"><i class="fa fa-check"></i><b>3.2</b> Bernoulli Model<span></span></a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="bernoulli-model.html"><a href="bernoulli-model.html#the-linear-probability-model"><i class="fa fa-check"></i><b>3.2.1</b> The Linear Probability Model<span></span></a></li>
<li class="chapter" data-level="3.2.2" data-path="bernoulli-model.html"><a href="bernoulli-model.html#the-logit-model"><i class="fa fa-check"></i><b>3.2.2</b> The Logit Model<span></span></a></li>
<li class="chapter" data-level="3.2.3" data-path="bernoulli-model.html"><a href="bernoulli-model.html#fitting-a-logit-model"><i class="fa fa-check"></i><b>3.2.3</b> Fitting a Logit Model<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="poisson-model.html"><a href="poisson-model.html"><i class="fa fa-check"></i><b>3.3</b> Poisson Model<span></span></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="poisson-model.html"><a href="poisson-model.html#predictive-distribution-1"><i class="fa fa-check"></i><b>3.3.1</b> Predictive Distribution<span></span></a></li>
<li class="chapter" data-level="3.3.2" data-path="poisson-model.html"><a href="poisson-model.html#posterior-predictive-distribution"><i class="fa fa-check"></i><b>3.3.2</b> Posterior Predictive Distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="posterior-predictive-distribution-1.html"><a href="posterior-predictive-distribution-1.html"><i class="fa fa-check"></i><b>3.4</b> [Posterior] Predictive Distribution<span></span></a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="posterior-predictive-distribution-1.html"><a href="posterior-predictive-distribution-1.html#for-the-logit-model"><i class="fa fa-check"></i><b>3.4.1</b> … for the logit model<span></span></a></li>
<li class="chapter" data-level="3.4.2" data-path="posterior-predictive-distribution-1.html"><a href="posterior-predictive-distribution-1.html#for-the-poisson-model"><i class="fa fa-check"></i><b>3.4.2</b> … for the Poisson model<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="quantities-of-interest.html"><a href="quantities-of-interest.html"><i class="fa fa-check"></i><b>3.5</b> Quantities of Interest<span></span></a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="quantities-of-interest.html"><a href="quantities-of-interest.html#expected-value"><i class="fa fa-check"></i><b>3.5.1</b> Expected Value<span></span></a></li>
<li class="chapter" data-level="3.5.2" data-path="quantities-of-interest.html"><a href="quantities-of-interest.html#first-difference"><i class="fa fa-check"></i><b>3.5.2</b> First Difference<span></span></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Modeling: A Tools Approach</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bernoulli-model" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Bernoulli Model<a href="bernoulli-model.html#bernoulli-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the case of the normal model, we used <span class="math inline">\(y_i \sim N(\mu_i, \sigma^2)\)</span>, where <span class="math inline">\(\mu_i = X_i\beta\)</span>. The normal model does a great job with roughly continuous outcomes like ENEP.</p>
<p>But sometimes we care about <strong>binary outcomes</strong>.</p>
<ul>
<li>Binary outcomes are categorical outcome variables with exactly two categories, such as whether or not someone voted, whether two countries are at war, and so on.</li>
<li>These variables are usually coded as <span class="math inline">\(y_i \in \{0, 1\}\)</span>, with one representing “an event” and zero representing “a non-event.”</li>
<li>In generic language, we’ll say that <span class="math inline">\(y_i = 1\)</span> means that “an event has occurred” and <span class="math inline">\(y_i = 0\)</span> means that “an event has not occurred.”</li>
<li>This allows us to talk about the “probability of an event” (e.g., the probability of war, etc)</li>
</ul>
<p>The normal model cannot describe a binary outcome well. But it doesn’t make much conceptual sense to model 0s and 1s as following a normal distribution.</p>
<div id="the-linear-probability-model" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> The Linear Probability Model<a href="bernoulli-model.html#the-linear-probability-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can use the linear model (i.e., OLS) with binary outcome variables.</p>
<ul>
<li>Recall that we the linear model is represented by the equation <span class="math inline">\(E(y_i) = X_i\beta\)</span>.</li>
<li>It is important to note that a probability is just a particular kind of expected value—a probability is an expected value of a binary variable.</li>
<li>Since <span class="math inline">\(y_i\)</span> is binary, the <span class="math inline">\(E(y_i) = \Pr(y_i = 1) = \Pr(y_i)\)</span>, giving us <span class="math inline">\(\Pr(y_i) = X_i\beta\)</span>.</li>
</ul>
<p>The LPM has two advantages:</p>
<ol style="list-style-type: decimal">
<li>It’s is <em>very</em> easy to estimate (i.e., OLS; <span class="math inline">\(\hat{\beta} = (X&#39;X)^{-1}X&#39;y\)</span>).</li>
<li>It is easy to interpret (i.e., a one unit change in <span class="math inline">\(x_j\)</span> leads to a <span class="math inline">\(\hat{\beta_j}\)</span> unit increase in <span class="math inline">\(\Pr(y)\)</span>).</li>
</ol>
<p>The LPM has several disadvantages</p>
<ol style="list-style-type: decimal">
<li><strong>Unbounded Predictions</strong> Because the potential values for the explanatory variables are unbounded, you can obtain predicted probabilities above one and below zero. Of course, these predictions make no sense.</li>
<li><strong>Conditional Heteroskedasticity</strong> The normal-linear model assumes a constant variance <span class="math inline">\(\sigma^2\)</span>. However, it is impossible to have homoskedastic residuals of a binary outcome if the probability of an event varies. Specifically, if <span class="math inline">\(y_i\)</span> is binary, then <span class="math inline">\(\text{Var}(y_i) = \Pr(y_i)[1 - \Pr(y_i)]\)</span>, which, for the LPM, equals <span class="math inline">\(X_i\beta(1 - X_i\beta)\)</span>. (Non-zero coefficients imply heteroskedasticity.)</li>
<li><strong>Non-Normal Errors</strong> Normal errors implies that the residuals can take on any value along the real line, with values closer to zero being more likely and errors outside three standard deviations being quite unlikely. However, if <span class="math inline">\(y_i\)</span> is binary, then the residual can take on only two values: <span class="math inline">\(-Pr(y_i)\)</span> or <span class="math inline">\(1 - Pr(y_i)\)</span>.</li>
<li><strong>Functional Form</strong> Theoretically, you’d probably expect explanatory variables to have smaller effects as <span class="math inline">\(Pr(y_i)\)</span> approaches zero or one (called “compression”). The LPM assumes that the effects are constant.</li>
</ol>
<p>Let’s fit the normal model to data from Wolfinger and Rosenstone (1993), Nagler (1994, the “Scobit” paper), and Berry, DeMeritt, and Esarey (2010).</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="bernoulli-model.html#cb125-1" aria-hidden="true" tabindex="-1"></a>scobit <span class="ot">&lt;-</span> haven<span class="sc">::</span><span class="fu">read_dta</span>(<span class="st">&quot;data/scobit.dta&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb125-2"><a href="bernoulli-model.html#cb125-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(newvote <span class="sc">!=</span> <span class="sc">-</span><span class="dv">1</span>) <span class="sc">%&gt;%</span>  <span class="co"># weird -1s in data; unsure if sufficient</span></span>
<span id="cb125-3"><a href="bernoulli-model.html#cb125-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glimpse</span>()</span></code></pre></div>
<pre><code>## Rows: 99,676
## Columns: 16
## $ state    &lt;dbl&gt; 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 9…
## $ vote     &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2…
## $ age      &lt;dbl&gt; 60, 80, 32, 25, 55, 63, 20, 53, 49, 27, 58, 56, 34, 34, 35, 3…
## $ educ     &lt;dbl&gt; 13, 13, 13, 13, 11, 14, 11, 11, 13, 13, 11, 13, 19, 19, 15, 1…
## $ citizen  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ rweight  &lt;dbl&gt; 207134, 215836, 184639, 184883, 168557, 179148, 181510, 19285…
## $ south    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
## $ gov      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
## $ closing  &lt;dbl&gt; 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2…
## $ age2     &lt;dbl&gt; 3600, 6400, 1024, 625, 3025, 3969, 400, 2809, 2401, 729, 3364…
## $ educ2    &lt;dbl&gt; 25, 25, 25, 25, 16, 36, 16, 16, 25, 25, 16, 25, 64, 64, 36, 2…
## $ cloeduc  &lt;dbl&gt; 145, 145, 145, 145, 116, 174, 116, 116, 145, 145, 116, 145, 2…
## $ cloeduc2 &lt;dbl&gt; 725, 725, 725, 725, 464, 1044, 464, 464, 725, 725, 464, 725, …
## $ newvote  &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0…
## $ newage   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
## $ neweduc  &lt;dbl&gt; 5, 5, 5, 5, 4, 6, 4, 4, 5, 5, 4, 5, 8, 8, 6, 5, 5, 3, 5, 1, 6…</code></pre>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="bernoulli-model.html#cb127-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> newvote <span class="sc">~</span> <span class="fu">poly</span>(neweduc, <span class="dv">2</span>, <span class="at">raw =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> closing <span class="sc">+</span> <span class="fu">poly</span>(age, <span class="dv">2</span>, <span class="at">raw =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> south <span class="sc">+</span> gov</span>
<span id="cb127-2"><a href="bernoulli-model.html#cb127-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(f, <span class="at">data =</span> scobit)</span>
<span id="cb127-3"><a href="bernoulli-model.html#cb127-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-4"><a href="bernoulli-model.html#cb127-4" aria-hidden="true" tabindex="-1"></a>mu_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit)  <span class="co"># the linear predictor for each row of data frame</span></span>
<span id="cb127-5"><a href="bernoulli-model.html#cb127-5" aria-hidden="true" tabindex="-1"></a>sigma_hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(<span class="fu">residuals</span>(fit)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb127-6"><a href="bernoulli-model.html#cb127-6" aria-hidden="true" tabindex="-1"></a>y_tilde <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">nrow</span>(scobit), mu_hat, sigma_hat)</span>
<span id="cb127-7"><a href="bernoulli-model.html#cb127-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-8"><a href="bernoulli-model.html#cb127-8" aria-hidden="true" tabindex="-1"></a><span class="co"># note: the code below uses variables NOT in the data frame; this is sloppy</span></span>
<span id="cb127-9"><a href="bernoulli-model.html#cb127-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb127-10"><a href="bernoulli-model.html#cb127-10" aria-hidden="true" tabindex="-1"></a>gg1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(scobit, <span class="fu">aes</span>(<span class="at">x =</span> mu_hat, <span class="at">y =</span> newvote)) <span class="sc">+</span> </span>
<span id="cb127-11"><a href="bernoulli-model.html#cb127-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">height =</span> <span class="fl">0.05</span>, <span class="at">alpha =</span> <span class="fl">0.1</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">size =</span> <span class="fl">0.3</span>)</span>
<span id="cb127-12"><a href="bernoulli-model.html#cb127-12" aria-hidden="true" tabindex="-1"></a>gg2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(scobit, <span class="fu">aes</span>(<span class="at">x =</span> mu_hat, <span class="at">y =</span> y_tilde)) <span class="sc">+</span> </span>
<span id="cb127-13"><a href="bernoulli-model.html#cb127-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.1</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">size =</span> <span class="fl">0.3</span>)</span>
<span id="cb127-14"><a href="bernoulli-model.html#cb127-14" aria-hidden="true" tabindex="-1"></a>gg1 <span class="sc">+</span> gg2</span></code></pre></div>
<p><img src="03-02-bernoulli-model_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>rstanarm has a convenient <code>pp_check()</code> function that allows you to compare the posterior predictive distribution to the observed distribution.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="bernoulli-model.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rstanarm); <span class="fu">options</span>(<span class="at">mc.cores =</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>())</span>
<span id="cb128-2"><a href="bernoulli-model.html#cb128-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-3"><a href="bernoulli-model.html#cb128-3" aria-hidden="true" tabindex="-1"></a>stan_fit <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(f, <span class="at">data =</span> scobit, <span class="at">family =</span> <span class="st">&quot;gaussian&quot;</span>, <span class="at">chains =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="bernoulli-model.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(stan_fit)</span></code></pre></div>
<p><img src="03-02-bernoulli-model_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="the-logit-model" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> The Logit Model<a href="bernoulli-model.html#the-logit-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As an initial effort to handle the “non-normal” distribution of the data, we might then use the Bernoulli model <span class="math inline">\(y_i \sim \text{Bernoulli}(\pi_i)\)</span>, where <span class="math inline">\(\pi_i = X_i\beta\)</span>. However, this has a <em>big</em> problem that can make the approach unworkable: <span class="math inline">\(X_i\beta\)</span> might be less than zero or greater than one.</p>
<p>To address bounds of <span class="math inline">\(\pi_i\)</span> and <span class="math inline">\(X_i\beta\)</span>, we are going to introduce a new concept called the “inverse link function.” Many of the “disadvantages” of the LPM above follow from the fact that the linear predictor is unbounded. For the normal model, the inverse link function is <strong>not necessary</strong> because the parameter of interest <span class="math inline">\(\mu\)</span> is unbounded and maps to the entire real line. But for other models, the key parameter has a restricted domain. In the case of the Bernoulli distribution, <span class="math inline">\(\pi_i \in [0, 1] \subset \mathbb{R}\)</span>.</p>
<p>The idea of the inverse link function is to wrap around the linear predictor and force its values into the desired domain.</p>
<p>For the Bernoulli distribution, we might use the inverse link function <span class="math inline">\(g^{-1}(x) = \frac{e^x}{1 + e^x}\)</span>. This is called the “inverse logit” and it has an “S”-shape. It’s job is to map <span class="math inline">\(X\beta\)</span> into <span class="math inline">\([0, 1]\)</span>. (It’s also the cdf of the standard logistic distribution.)</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="bernoulli-model.html#cb130-1" aria-hidden="true" tabindex="-1"></a>inv_logit <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb130-2"><a href="bernoulli-model.html#cb130-2" aria-hidden="true" tabindex="-1"></a>  (<span class="fu">exp</span>(x))<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x))</span>
<span id="cb130-3"><a href="bernoulli-model.html#cb130-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb130-4"><a href="bernoulli-model.html#cb130-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-5"><a href="bernoulli-model.html#cb130-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb130-6"><a href="bernoulli-model.html#cb130-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>) <span class="sc">+</span> </span>
<span id="cb130-7"><a href="bernoulli-model.html#cb130-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> inv_logit)</span></code></pre></div>
<p><img src="03-02-bernoulli-model_files/figure-html/unnamed-chunk-5-1.png" width="288" /></p>
<p>Hint: The inverse-logit function is the cdf of the standard logistic distribution, so you can just use <code>plogis()</code> in R, rather than hard-coding the <code>inv_logit()</code> function I create above.</p>
<p>Swapping the normal distribution for the Bernoulli and adding the inverse-logit inverse-link function gives us the logit model (or “logistic regression”).</p>
<p><span class="math display">\[
y_i \sim \text{Bernoulli}(\pi_i)\text{, where } \pi_i = \text{logit}^{-1}(X_i\beta).
\]</span></p>
<p>We can fit this model using maximum likelihood or posterior simulation.</p>
</div>
<div id="fitting-a-logit-model" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Fitting a Logit Model<a href="bernoulli-model.html#fitting-a-logit-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="with-optim" class="section level4 hasAnchor" number="3.2.3.1">
<h4><span class="header-section-number">3.2.3.1</span> With <code>optim()</code><a href="bernoulli-model.html#with-optim" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To develop the log-likelihood of the logit model, we start with the Bernoulli likelihood from Week 1.</p>
<p><span class="math display">\[
f(y; \beta) = L(\beta) = \prod_{i = 1}^{N}\pi_i^{y_i} (1 - \pi_i)^{(1 - y_i)}\text{, where } \pi_i = \text{logit}^{-1}(X_i\beta)
\]</span>
Taking the log, we have</p>
<p><span class="math display">\[
\log L(\beta) = \sum_{i = 1}^{N} y_i \log \pi_i +  \sum_{i = 1}^{N}(1 - y_i) \log(1 - \pi_i)\text{, where } \pi_i = \text{logit}^{-1}(X_i\beta)
\]</span>
We can program this into R for use in <code>optim()</code>.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="bernoulli-model.html#cb131-1" aria-hidden="true" tabindex="-1"></a>logit_ll <span class="ot">&lt;-</span> <span class="cf">function</span>(beta, y, X) {</span>
<span id="cb131-2"><a href="bernoulli-model.html#cb131-2" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">plogis</span>(X<span class="sc">%*%</span>beta)  <span class="co"># pi is special in R, so I use p</span></span>
<span id="cb131-3"><a href="bernoulli-model.html#cb131-3" aria-hidden="true" tabindex="-1"></a>  ll <span class="ot">&lt;-</span> <span class="fu">sum</span>(y<span class="sc">*</span><span class="fu">log</span>(p)) <span class="sc">+</span> <span class="fu">sum</span>((<span class="dv">1</span> <span class="sc">-</span> y)<span class="sc">*</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> p))</span>
<span id="cb131-4"><a href="bernoulli-model.html#cb131-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(ll)</span>
<span id="cb131-5"><a href="bernoulli-model.html#cb131-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb131-6"><a href="bernoulli-model.html#cb131-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-7"><a href="bernoulli-model.html#cb131-7" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively</span></span>
<span id="cb131-8"><a href="bernoulli-model.html#cb131-8" aria-hidden="true" tabindex="-1"></a>logit_ll2 <span class="ot">&lt;-</span> <span class="cf">function</span>(beta, y, X) {</span>
<span id="cb131-9"><a href="bernoulli-model.html#cb131-9" aria-hidden="true" tabindex="-1"></a>  ll <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">dbinom</span>(y, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> <span class="fu">plogis</span>(X<span class="sc">%*%</span>beta), <span class="at">log =</span> <span class="cn">TRUE</span>))  <span class="co"># easier to use R&#39;s d*() functions</span></span>
<span id="cb131-10"><a href="bernoulli-model.html#cb131-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(ll)</span>
<span id="cb131-11"><a href="bernoulli-model.html#cb131-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The tricky part about using <code>optim()</code> here is not the log-likelihood function, but setting up <code>X</code> and <code>y</code>. The code below creates the outcome vector <span class="math inline">\(y\)</span> and the matrix <span class="math inline">\(X\)</span> of explanatory variables (with a leading columns of 1s).</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="bernoulli-model.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create formula</span></span>
<span id="cb132-2"><a href="bernoulli-model.html#cb132-2" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> newvote <span class="sc">~</span> <span class="fu">poly</span>(neweduc, <span class="dv">2</span>, <span class="at">raw =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> closing <span class="sc">+</span> <span class="fu">poly</span>(age, <span class="dv">2</span>, <span class="at">raw =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> south <span class="sc">+</span> gov</span>
<span id="cb132-3"><a href="bernoulli-model.html#cb132-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-4"><a href="bernoulli-model.html#cb132-4" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain the model matrix X</span></span>
<span id="cb132-5"><a href="bernoulli-model.html#cb132-5" aria-hidden="true" tabindex="-1"></a>mf <span class="ot">&lt;-</span> <span class="fu">model.frame</span>(f, <span class="at">data =</span> scobit)  <span class="co"># model frame</span></span>
<span id="cb132-6"><a href="bernoulli-model.html#cb132-6" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(f, mf)         <span class="co"># model matrix X</span></span>
<span id="cb132-7"><a href="bernoulli-model.html#cb132-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-8"><a href="bernoulli-model.html#cb132-8" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain the outcome variable y</span></span>
<span id="cb132-9"><a href="bernoulli-model.html#cb132-9" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">model.response</span>(mf)</span></code></pre></div>
<p>Then we can use <code>optim()</code>.</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="bernoulli-model.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="co"># for some reason, this isn&#39;t converging</span></span>
<span id="cb133-2"><a href="bernoulli-model.html#cb133-2" aria-hidden="true" tabindex="-1"></a>par_start <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">ncol</span>(X) <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb133-3"><a href="bernoulli-model.html#cb133-3" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">&lt;-</span> <span class="fu">optim</span>(par_start, <span class="at">fn =</span> logit_ll, <span class="at">y =</span> y, <span class="at">X =</span> X, </span>
<span id="cb133-4"><a href="bernoulli-model.html#cb133-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">control =</span> <span class="fu">list</span>(<span class="at">fnscale =</span> <span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb133-5"><a href="bernoulli-model.html#cb133-5" aria-hidden="true" tabindex="-1"></a>opt<span class="sc">$</span>par</span></code></pre></div>
<pre><code>## [1] -3.0546169207  0.2735676715  0.0209478540 -0.0216067192  0.0807472482
## [6] -0.0004976604 -0.0467922614 -0.0362716220</code></pre>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="bernoulli-model.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test w/ same X and y; works</span></span>
<span id="cb135-2"><a href="bernoulli-model.html#cb135-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">glm.fit</span>(X, y, <span class="at">family =</span> <span class="fu">binomial</span>()))</span></code></pre></div>
<pre><code>##                   (Intercept) poly(neweduc, 2, raw = TRUE)1 
##                 -4.0727861365                  0.2426335636 
## poly(neweduc, 2, raw = TRUE)2                       closing 
##                  0.0282045522                 -0.0132046240 
##     poly(age, 2, raw = TRUE)1     poly(age, 2, raw = TRUE)2 
##                  0.1142218082                 -0.0008222347 
##                         south                           gov 
##                 -0.1904026537                  0.0052717028</code></pre>
</div>
<div id="with-glm" class="section level4 hasAnchor" number="3.2.3.2">
<h4><span class="header-section-number">3.2.3.2</span> With <code>glm()</code><a href="bernoulli-model.html#with-glm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="bernoulli-model.html#cb137-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(f, <span class="at">data =</span> scobit, <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb137-2"><a href="bernoulli-model.html#cb137-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fit)</span></code></pre></div>
<pre><code>##                   (Intercept) poly(neweduc, 2, raw = TRUE)1 
##                 -4.0727861365                  0.2426335636 
## poly(neweduc, 2, raw = TRUE)2                       closing 
##                  0.0282045522                 -0.0132046240 
##     poly(age, 2, raw = TRUE)1     poly(age, 2, raw = TRUE)2 
##                  0.1142218082                 -0.0008222347 
##                         south                           gov 
##                 -0.1904026537                  0.0052717028</code></pre>
</div>
<div id="with-stan" class="section level4 hasAnchor" number="3.2.3.3">
<h4><span class="header-section-number">3.2.3.3</span> With Stan<a href="bernoulli-model.html#with-stan" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="bernoulli-model.html#cb139-1" aria-hidden="true" tabindex="-1"></a>small_scobit <span class="ot">&lt;-</span> <span class="fu">sample_n</span>(scobit, <span class="dv">1000</span>)</span>
<span id="cb139-2"><a href="bernoulli-model.html#cb139-2" aria-hidden="true" tabindex="-1"></a>stan_fit <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(f, <span class="at">data =</span> small_scobit, <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="bernoulli-model.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(stan_fit)</span></code></pre></div>
<pre><code>## 
## Model Info:
##  function:     stan_glm
##  family:       binomial [logit]
##  formula:      newvote ~ poly(neweduc, 2, raw = TRUE) + closing + poly(age, 
##     2, raw = TRUE) + south + gov
##  algorithm:    sampling
##  sample:       4000 (posterior sample size)
##  priors:       see help(&#39;prior_summary&#39;)
##  observations: 1000
##  predictors:   8
## 
## Estimates:
##                                 mean   sd   10%   50%   90%
## (Intercept)                   -4.7    0.8 -5.7  -4.7  -3.7 
## poly(neweduc, 2, raw = TRUE)1  0.6    0.3  0.2   0.6   0.9 
## poly(neweduc, 2, raw = TRUE)2  0.0    0.0  0.0   0.0   0.0 
## closing                        0.0    0.0  0.0   0.0   0.0 
## poly(age, 2, raw = TRUE)1      0.1    0.0  0.1   0.1   0.1 
## poly(age, 2, raw = TRUE)2      0.0    0.0  0.0   0.0   0.0 
## south                         -0.2    0.2 -0.5  -0.2   0.0 
## gov                            0.1    0.2 -0.2   0.1   0.3 
## 
## Fit Diagnostics:
##            mean   sd   10%   50%   90%
## mean_PPD 0.7    0.0  0.7   0.7   0.7  
## 
## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)).
## 
## MCMC diagnostics
##                               mcse Rhat n_eff
## (Intercept)                   0.0  1.0  2512 
## poly(neweduc, 2, raw = TRUE)1 0.0  1.0  2283 
## poly(neweduc, 2, raw = TRUE)2 0.0  1.0  2261 
## closing                       0.0  1.0  4103 
## poly(age, 2, raw = TRUE)1     0.0  1.0  2185 
## poly(age, 2, raw = TRUE)2     0.0  1.0  2177 
## south                         0.0  1.0  3628 
## gov                           0.0  1.0  3843 
## mean_PPD                      0.0  1.0  4002 
## log-posterior                 0.0  1.0  1930 
## 
## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="review-the-normal-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="poisson-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
